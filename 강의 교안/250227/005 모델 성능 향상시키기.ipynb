{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ftw5hyfw_nGs"
   },
   "source": [
    "# 모델의 성능 향상시키기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lD8i9xrq_nGw"
   },
   "source": [
    "### 1. 데이터의 확인과 검증셋"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "executionInfo": {
     "elapsed": 4797,
     "status": "ok",
     "timestamp": 1690333106925,
     "user": {
      "displayName": "junhwa lee",
      "userId": "11332889748979012167"
     },
     "user_tz": -540
    },
    "id": "9Usj9sc8_nGx",
    "outputId": "2289445b-bf2d-43b8-ab2e-50173f9c77fb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.99680</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.99700</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.99800</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6492</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.039</td>\n",
       "      <td>24.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>0.99114</td>\n",
       "      <td>3.27</td>\n",
       "      <td>0.50</td>\n",
       "      <td>11.2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6493</th>\n",
       "      <td>6.6</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.36</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.047</td>\n",
       "      <td>57.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>0.99490</td>\n",
       "      <td>3.15</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.6</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6494</th>\n",
       "      <td>6.5</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.19</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.041</td>\n",
       "      <td>30.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>0.99254</td>\n",
       "      <td>2.99</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6495</th>\n",
       "      <td>5.5</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.022</td>\n",
       "      <td>20.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.98869</td>\n",
       "      <td>3.34</td>\n",
       "      <td>0.38</td>\n",
       "      <td>12.8</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6496</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.020</td>\n",
       "      <td>22.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0.98941</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.32</td>\n",
       "      <td>11.8</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6497 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0     1     2    3      4     5      6        7     8     9     10  \\\n",
       "0      7.4  0.70  0.00  1.9  0.076  11.0   34.0  0.99780  3.51  0.56   9.4   \n",
       "1      7.8  0.88  0.00  2.6  0.098  25.0   67.0  0.99680  3.20  0.68   9.8   \n",
       "2      7.8  0.76  0.04  2.3  0.092  15.0   54.0  0.99700  3.26  0.65   9.8   \n",
       "3     11.2  0.28  0.56  1.9  0.075  17.0   60.0  0.99800  3.16  0.58   9.8   \n",
       "4      7.4  0.70  0.00  1.9  0.076  11.0   34.0  0.99780  3.51  0.56   9.4   \n",
       "...    ...   ...   ...  ...    ...   ...    ...      ...   ...   ...   ...   \n",
       "6492   6.2  0.21  0.29  1.6  0.039  24.0   92.0  0.99114  3.27  0.50  11.2   \n",
       "6493   6.6  0.32  0.36  8.0  0.047  57.0  168.0  0.99490  3.15  0.46   9.6   \n",
       "6494   6.5  0.24  0.19  1.2  0.041  30.0  111.0  0.99254  2.99  0.46   9.4   \n",
       "6495   5.5  0.29  0.30  1.1  0.022  20.0  110.0  0.98869  3.34  0.38  12.8   \n",
       "6496   6.0  0.21  0.38  0.8  0.020  22.0   98.0  0.98941  3.26  0.32  11.8   \n",
       "\n",
       "      11  12  \n",
       "0      5   1  \n",
       "1      5   1  \n",
       "2      5   1  \n",
       "3      6   1  \n",
       "4      5   1  \n",
       "...   ..  ..  \n",
       "6492   6   0  \n",
       "6493   5   0  \n",
       "6494   6   0  \n",
       "6495   7   0  \n",
       "6496   6   0  \n",
       "\n",
       "[6497 rows x 13 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "# 와인 데이터를 불러옵니다.\n",
    "df = pd.read_csv('./data/wine.csv', header=None)\n",
    "\n",
    "# 데이터를 미리 보겠습니다.\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 380,
     "status": "ok",
     "timestamp": 1690333109692,
     "user": {
      "displayName": "junhwa lee",
      "userId": "11332889748979012167"
     },
     "user_tz": -540
    },
    "id": "m0ZlAXHN_nGy"
   },
   "outputs": [],
   "source": [
    "# 와인의 속성을 X로 와인의 분류를 y로 저장합니다.\n",
    "X = df.iloc[:,0:12]\n",
    "y = df.iloc[:,12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6935,
     "status": "ok",
     "timestamp": 1690333118735,
     "user": {
      "displayName": "junhwa lee",
      "userId": "11332889748979012167"
     },
     "user_tz": -540
    },
    "id": "TpeC4rTC_nGz",
    "outputId": "4e59866f-ddbe-4077-bd67-d74be06a61fb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">390</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">372</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">104</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │               <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)                  │             \u001b[38;5;34m390\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m)                  │             \u001b[38;5;34m372\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)                   │             \u001b[38;5;34m104\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │               \u001b[38;5;34m9\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">875</span> (3.42 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m875\u001b[0m (3.42 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">875</span> (3.42 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m875\u001b[0m (3.42 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.2447 - loss: 6.9756 - val_accuracy: 0.2300 - val_loss: 3.4066\n",
      "Epoch 2/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.2804 - loss: 2.3518 - val_accuracy: 0.8269 - val_loss: 0.4742\n",
      "Epoch 3/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8162 - loss: 0.4593 - val_accuracy: 0.8146 - val_loss: 0.4240\n",
      "Epoch 4/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7949 - loss: 0.4412 - val_accuracy: 0.8238 - val_loss: 0.4016\n",
      "Epoch 5/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8105 - loss: 0.4171 - val_accuracy: 0.8377 - val_loss: 0.3790\n",
      "Epoch 6/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8340 - loss: 0.3852 - val_accuracy: 0.8492 - val_loss: 0.3573\n",
      "Epoch 7/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8382 - loss: 0.3762 - val_accuracy: 0.8608 - val_loss: 0.3386\n",
      "Epoch 8/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8447 - loss: 0.3569 - val_accuracy: 0.8685 - val_loss: 0.3235\n",
      "Epoch 9/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8538 - loss: 0.3445 - val_accuracy: 0.8769 - val_loss: 0.3097\n",
      "Epoch 10/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8624 - loss: 0.3361 - val_accuracy: 0.8815 - val_loss: 0.2968\n",
      "Epoch 11/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8764 - loss: 0.3171 - val_accuracy: 0.8862 - val_loss: 0.2854\n",
      "Epoch 12/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8773 - loss: 0.3102 - val_accuracy: 0.8931 - val_loss: 0.2746\n",
      "Epoch 13/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8827 - loss: 0.3052 - val_accuracy: 0.8969 - val_loss: 0.2649\n",
      "Epoch 14/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8879 - loss: 0.2879 - val_accuracy: 0.8969 - val_loss: 0.2548\n",
      "Epoch 15/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9009 - loss: 0.2649 - val_accuracy: 0.9031 - val_loss: 0.2453\n",
      "Epoch 16/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9055 - loss: 0.2641 - val_accuracy: 0.9092 - val_loss: 0.2365\n",
      "Epoch 17/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9098 - loss: 0.2529 - val_accuracy: 0.9138 - val_loss: 0.2269\n",
      "Epoch 18/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9171 - loss: 0.2417 - val_accuracy: 0.9192 - val_loss: 0.2195\n",
      "Epoch 19/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9138 - loss: 0.2536 - val_accuracy: 0.9269 - val_loss: 0.2089\n",
      "Epoch 20/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9178 - loss: 0.2465 - val_accuracy: 0.9323 - val_loss: 0.2008\n",
      "Epoch 21/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9226 - loss: 0.2310 - val_accuracy: 0.9369 - val_loss: 0.1950\n",
      "Epoch 22/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9180 - loss: 0.2354 - val_accuracy: 0.9415 - val_loss: 0.1907\n",
      "Epoch 23/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9250 - loss: 0.2174 - val_accuracy: 0.9431 - val_loss: 0.1861\n",
      "Epoch 24/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9263 - loss: 0.2251 - val_accuracy: 0.9415 - val_loss: 0.1828\n",
      "Epoch 25/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9308 - loss: 0.2143 - val_accuracy: 0.9446 - val_loss: 0.1807\n",
      "Epoch 26/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9332 - loss: 0.2033 - val_accuracy: 0.9431 - val_loss: 0.1778\n",
      "Epoch 27/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9304 - loss: 0.2105 - val_accuracy: 0.9431 - val_loss: 0.1760\n",
      "Epoch 28/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9298 - loss: 0.2076 - val_accuracy: 0.9423 - val_loss: 0.1743\n",
      "Epoch 29/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9368 - loss: 0.1949 - val_accuracy: 0.9446 - val_loss: 0.1718\n",
      "Epoch 30/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9399 - loss: 0.1896 - val_accuracy: 0.9431 - val_loss: 0.1711\n",
      "Epoch 31/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9344 - loss: 0.2023 - val_accuracy: 0.9431 - val_loss: 0.1697\n",
      "Epoch 32/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9400 - loss: 0.1831 - val_accuracy: 0.9446 - val_loss: 0.1676\n",
      "Epoch 33/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9364 - loss: 0.1917 - val_accuracy: 0.9438 - val_loss: 0.1680\n",
      "Epoch 34/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9312 - loss: 0.2028 - val_accuracy: 0.9431 - val_loss: 0.1661\n",
      "Epoch 35/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9326 - loss: 0.1971 - val_accuracy: 0.9438 - val_loss: 0.1646\n",
      "Epoch 36/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9366 - loss: 0.1982 - val_accuracy: 0.9431 - val_loss: 0.1637\n",
      "Epoch 37/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9278 - loss: 0.2084 - val_accuracy: 0.9438 - val_loss: 0.1629\n",
      "Epoch 38/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9340 - loss: 0.1939 - val_accuracy: 0.9438 - val_loss: 0.1619\n",
      "Epoch 39/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9355 - loss: 0.1928 - val_accuracy: 0.9446 - val_loss: 0.1610\n",
      "Epoch 40/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9405 - loss: 0.1844 - val_accuracy: 0.9446 - val_loss: 0.1598\n",
      "Epoch 41/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9356 - loss: 0.1875 - val_accuracy: 0.9438 - val_loss: 0.1603\n",
      "Epoch 42/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9403 - loss: 0.1831 - val_accuracy: 0.9454 - val_loss: 0.1586\n",
      "Epoch 43/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9442 - loss: 0.1726 - val_accuracy: 0.9454 - val_loss: 0.1580\n",
      "Epoch 44/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9350 - loss: 0.1895 - val_accuracy: 0.9454 - val_loss: 0.1571\n",
      "Epoch 45/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9383 - loss: 0.1844 - val_accuracy: 0.9462 - val_loss: 0.1563\n",
      "Epoch 46/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9389 - loss: 0.1804 - val_accuracy: 0.9454 - val_loss: 0.1554\n",
      "Epoch 47/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9372 - loss: 0.1875 - val_accuracy: 0.9462 - val_loss: 0.1558\n",
      "Epoch 48/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9456 - loss: 0.1672 - val_accuracy: 0.9454 - val_loss: 0.1533\n",
      "Epoch 49/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9366 - loss: 0.1833 - val_accuracy: 0.9462 - val_loss: 0.1539\n",
      "Epoch 50/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9365 - loss: 0.1764 - val_accuracy: 0.9462 - val_loss: 0.1522\n"
     ]
    }
   ],
   "source": [
    "# 학습셋과 테스트셋으로 나눕니다.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True)\n",
    "\n",
    "# 모델 구조를 설정합니다.\n",
    "model = Sequential()\n",
    "model.add(Dense(30,  input_dim=12, activation='relu'))\n",
    "model.add(Dense(12, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.summary()\n",
    "\n",
    "# 모델을 컴파일합니다.\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# 모델을 실행합니다.\n",
    "history=model.fit(X_train, y_train, epochs=50, batch_size=500, validation_split=0.25) # 0.8 x 0.25 = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 385,
     "status": "ok",
     "timestamp": 1690333122290,
     "user": {
      "displayName": "junhwa lee",
      "userId": "11332889748979012167"
     },
     "user_tz": -540
    },
    "id": "Fqe8H_Cb_nGz",
    "outputId": "58b62b21-0a87-4de6-9b0e-149aa88b8eaa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9319 - loss: 0.1836 \n",
      "Test accuracy: 0.9330769181251526\n"
     ]
    }
   ],
   "source": [
    "# 테스트 결과를 출력합니다.\n",
    "score=model.evaluate(X_test, y_test)\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1nv462wz_nG0"
   },
   "source": [
    "## 2. 모델 업데이트하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jbJimFFF_nG1"
   },
   "source": [
    "### 기본 코드 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 383,
     "status": "ok",
     "timestamp": 1690333128648,
     "user": {
      "displayName": "junhwa lee",
      "userId": "11332889748979012167"
     },
     "user_tz": -540
    },
    "id": "AbHJ3gjb_nG1",
    "outputId": "7277ec77-9ece-4617-b274-ed370bb0f308"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">390</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">372</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">104</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │               <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)                  │             \u001b[38;5;34m390\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m)                  │             \u001b[38;5;34m372\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)                   │             \u001b[38;5;34m104\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │               \u001b[38;5;34m9\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">875</span> (3.42 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m875\u001b[0m (3.42 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">875</span> (3.42 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m875\u001b[0m (3.42 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# 와인 데이터를 불러옵니다.\n",
    "df = pd.read_csv('./data/wine.csv', header=None)\n",
    "\n",
    "# 와인의 속성을 X로 와인의 분류를 y로 저장합니다.\n",
    "X = df.iloc[:,0:12]\n",
    "y = df.iloc[:,12]\n",
    "\n",
    "# 학습셋과 테스트셋으로 나눕니다.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,\n",
    "                                                    shuffle=True)\n",
    "\n",
    "# 모델 구조를 설정합니다.\n",
    "model = Sequential()\n",
    "model.add(Dense(30,  input_dim=12, activation='relu'))\n",
    "model.add(Dense(12, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.summary()\n",
    "\n",
    "# 모델을 컴파일합니다.\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v8wHnkFW_nG2"
   },
   "source": [
    "### 모델의 저장 설정 및 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5658,
     "status": "ok",
     "timestamp": 1690333145538,
     "user": {
      "displayName": "junhwa lee",
      "userId": "11332889748979012167"
     },
     "user_tz": -540
    },
    "id": "cZ7qFKZe_nG2",
    "outputId": "a1ac2a31-928d-4d81-8b88-129805d8ea12"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: saving model to ./data/model/all/01-0.8769.keras\n",
      "\n",
      "Epoch 2: saving model to ./data/model/all/02-0.8308.keras\n",
      "\n",
      "Epoch 3: saving model to ./data/model/all/03-0.8846.keras\n",
      "\n",
      "Epoch 4: saving model to ./data/model/all/04-0.8969.keras\n",
      "\n",
      "Epoch 5: saving model to ./data/model/all/05-0.9015.keras\n",
      "\n",
      "Epoch 6: saving model to ./data/model/all/06-0.9046.keras\n",
      "\n",
      "Epoch 7: saving model to ./data/model/all/07-0.9062.keras\n",
      "\n",
      "Epoch 8: saving model to ./data/model/all/08-0.9100.keras\n",
      "\n",
      "Epoch 9: saving model to ./data/model/all/09-0.9169.keras\n",
      "\n",
      "Epoch 10: saving model to ./data/model/all/10-0.9192.keras\n",
      "\n",
      "Epoch 11: saving model to ./data/model/all/11-0.9215.keras\n",
      "\n",
      "Epoch 12: saving model to ./data/model/all/12-0.9246.keras\n",
      "\n",
      "Epoch 13: saving model to ./data/model/all/13-0.9262.keras\n",
      "\n",
      "Epoch 14: saving model to ./data/model/all/14-0.9277.keras\n",
      "\n",
      "Epoch 15: saving model to ./data/model/all/15-0.9277.keras\n",
      "\n",
      "Epoch 16: saving model to ./data/model/all/16-0.9285.keras\n",
      "\n",
      "Epoch 17: saving model to ./data/model/all/17-0.9300.keras\n",
      "\n",
      "Epoch 18: saving model to ./data/model/all/18-0.9300.keras\n",
      "\n",
      "Epoch 19: saving model to ./data/model/all/19-0.9300.keras\n",
      "\n",
      "Epoch 20: saving model to ./data/model/all/20-0.9308.keras\n",
      "\n",
      "Epoch 21: saving model to ./data/model/all/21-0.9308.keras\n",
      "\n",
      "Epoch 22: saving model to ./data/model/all/22-0.9308.keras\n",
      "\n",
      "Epoch 23: saving model to ./data/model/all/23-0.9315.keras\n",
      "\n",
      "Epoch 24: saving model to ./data/model/all/24-0.9323.keras\n",
      "\n",
      "Epoch 25: saving model to ./data/model/all/25-0.9315.keras\n",
      "\n",
      "Epoch 26: saving model to ./data/model/all/26-0.9323.keras\n",
      "\n",
      "Epoch 27: saving model to ./data/model/all/27-0.9331.keras\n",
      "\n",
      "Epoch 28: saving model to ./data/model/all/28-0.9323.keras\n",
      "\n",
      "Epoch 29: saving model to ./data/model/all/29-0.9315.keras\n",
      "\n",
      "Epoch 30: saving model to ./data/model/all/30-0.9338.keras\n",
      "\n",
      "Epoch 31: saving model to ./data/model/all/31-0.9338.keras\n",
      "\n",
      "Epoch 32: saving model to ./data/model/all/32-0.9331.keras\n",
      "\n",
      "Epoch 33: saving model to ./data/model/all/33-0.9338.keras\n",
      "\n",
      "Epoch 34: saving model to ./data/model/all/34-0.9338.keras\n",
      "\n",
      "Epoch 35: saving model to ./data/model/all/35-0.9338.keras\n",
      "\n",
      "Epoch 36: saving model to ./data/model/all/36-0.9338.keras\n",
      "\n",
      "Epoch 37: saving model to ./data/model/all/37-0.9338.keras\n",
      "\n",
      "Epoch 38: saving model to ./data/model/all/38-0.9331.keras\n",
      "\n",
      "Epoch 39: saving model to ./data/model/all/39-0.9346.keras\n",
      "\n",
      "Epoch 40: saving model to ./data/model/all/40-0.9346.keras\n",
      "\n",
      "Epoch 41: saving model to ./data/model/all/41-0.9346.keras\n",
      "\n",
      "Epoch 42: saving model to ./data/model/all/42-0.9346.keras\n",
      "\n",
      "Epoch 43: saving model to ./data/model/all/43-0.9346.keras\n",
      "\n",
      "Epoch 44: saving model to ./data/model/all/44-0.9346.keras\n",
      "\n",
      "Epoch 45: saving model to ./data/model/all/45-0.9354.keras\n",
      "\n",
      "Epoch 46: saving model to ./data/model/all/46-0.9354.keras\n",
      "\n",
      "Epoch 47: saving model to ./data/model/all/47-0.9346.keras\n",
      "\n",
      "Epoch 48: saving model to ./data/model/all/48-0.9346.keras\n",
      "\n",
      "Epoch 49: saving model to ./data/model/all/49-0.9362.keras\n",
      "\n",
      "Epoch 50: saving model to ./data/model/all/50-0.9354.keras\n"
     ]
    }
   ],
   "source": [
    "# 모델 저장의 조건을 설정합니다.\n",
    "modelpath=\"./data/model/all/{epoch:02d}-{val_accuracy:.4f}.keras\"\n",
    "checkpointer = ModelCheckpoint(filepath=modelpath, verbose=1)\n",
    "\n",
    "# 모델을 실행합니다.\n",
    "history=model.fit(X_train, y_train, epochs=50, batch_size=500, validation_split=0.25, verbose=0,\n",
    "                  callbacks=[checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 383,
     "status": "ok",
     "timestamp": 1690333149724,
     "user": {
      "displayName": "junhwa lee",
      "userId": "11332889748979012167"
     },
     "user_tz": -540
    },
    "id": "bcOwXzrp_nG3",
    "outputId": "b45fc2b1-47b0-4aec-8e23-bbc3ad0586ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9308 - loss: 0.1806 \n",
      "Test accuracy: 0.9276922941207886\n"
     ]
    }
   ],
   "source": [
    "# 테스트 결과를 출력합니다.\n",
    "score=model.evaluate(X_test, y_test)\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HX_DdAlb_nG3"
   },
   "source": [
    "## 3. 그래프로 과적합 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 202407,
     "status": "ok",
     "timestamp": 1690333370929,
     "user": {
      "displayName": "junhwa lee",
      "userId": "11332889748979012167"
     },
     "user_tz": -540
    },
    "id": "pDwxitjb_nG3",
    "outputId": "8aaede37-cd33-401c-d4db-c25dca959540"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/2000\n",
      "10/10 ━━━━━━━━━━━━━━━━━━━━ accuracy: 0.9633 - loss: 0.1121 - val_accuracy: 0.9562 - val_loss: 0.1066\n",
      "Epoch 100/2000\n",
      "10/10 ━━━━━━━━━━━━━━━━━━━━ accuracy: 0.9759 - loss: 0.0798 - val_accuracy: 0.9746 - val_loss: 0.0754\n",
      "Epoch 150/2000\n",
      "10/10 ━━━━━━━━━━━━━━━━━━━━ accuracy: 0.9808 - loss: 0.0671 - val_accuracy: 0.9762 - val_loss: 0.0682\n",
      "Epoch 200/2000\n",
      "10/10 ━━━━━━━━━━━━━━━━━━━━ accuracy: 0.9820 - loss: 0.0625 - val_accuracy: 0.9792 - val_loss: 0.0645\n",
      "Epoch 250/2000\n",
      "10/10 ━━━━━━━━━━━━━━━━━━━━ accuracy: 0.9820 - loss: 0.0604 - val_accuracy: 0.9792 - val_loss: 0.0599\n",
      "Epoch 300/2000\n",
      "10/10 ━━━━━━━━━━━━━━━━━━━━ accuracy: 0.9851 - loss: 0.0559 - val_accuracy: 0.9792 - val_loss: 0.0558\n",
      "Epoch 350/2000\n",
      "10/10 ━━━━━━━━━━━━━━━━━━━━ accuracy: 0.9846 - loss: 0.0536 - val_accuracy: 0.9831 - val_loss: 0.0555\n",
      "Epoch 400/2000\n",
      "10/10 ━━━━━━━━━━━━━━━━━━━━ accuracy: 0.9861 - loss: 0.0518 - val_accuracy: 0.9815 - val_loss: 0.0564\n",
      "Epoch 450/2000\n",
      "10/10 ━━━━━━━━━━━━━━━━━━━━ accuracy: 0.9874 - loss: 0.0485 - val_accuracy: 0.9823 - val_loss: 0.0571\n",
      "Epoch 500/2000\n",
      "10/10 ━━━━━━━━━━━━━━━━━━━━ accuracy: 0.9869 - loss: 0.0476 - val_accuracy: 0.9823 - val_loss: 0.0542\n",
      "Epoch 550/2000\n",
      "10/10 ━━━━━━━━━━━━━━━━━━━━ accuracy: 0.9867 - loss: 0.0468 - val_accuracy: 0.9831 - val_loss: 0.0546\n",
      "Epoch 600/2000\n",
      "10/10 ━━━━━━━━━━━━━━━━━━━━ accuracy: 0.9867 - loss: 0.0472 - val_accuracy: 0.9808 - val_loss: 0.0629\n",
      "Epoch 650/2000\n",
      "10/10 ━━━━━━━━━━━━━━━━━━━━ accuracy: 0.9879 - loss: 0.0436 - val_accuracy: 0.9846 - val_loss: 0.0553\n",
      "Epoch 700/2000\n",
      "10/10 ━━━━━━━━━━━━━━━━━━━━ accuracy: 0.9877 - loss: 0.0437 - val_accuracy: 0.9846 - val_loss: 0.0558\n",
      "Epoch 750/2000\n",
      "10/10 ━━━━━━━━━━━━━━━━━━━━ accuracy: 0.9895 - loss: 0.0426 - val_accuracy: 0.9846 - val_loss: 0.0548\n",
      "Epoch 800/2000\n",
      "10/10 ━━━━━━━━━━━━━━━━━━━━ accuracy: 0.9864 - loss: 0.0477 - val_accuracy: 0.9838 - val_loss: 0.0597\n",
      "Epoch 850/2000\n",
      "10/10 ━━━━━━━━━━━━━━━━━━━━ accuracy: 0.9856 - loss: 0.0437 - val_accuracy: 0.9831 - val_loss: 0.0570\n",
      "Epoch 900/2000\n",
      "10/10 ━━━━━━━━━━━━━━━━━━━━ accuracy: 0.9882 - loss: 0.0425 - val_accuracy: 0.9815 - val_loss: 0.0677\n",
      "Epoch 950/2000\n",
      "10/10 ━━━━━━━━━━━━━━━━━━━━ accuracy: 0.9885 - loss: 0.0415 - val_accuracy: 0.9838 - val_loss: 0.0594\n",
      "Epoch 1000/2000\n",
      "10/10 ━━━━━━━━━━━━━━━━━━━━ accuracy: 0.9895 - loss: 0.0402 - val_accuracy: 0.9838 - val_loss: 0.0594\n",
      "Epoch 1050/2000\n",
      "10/10 ━━━━━━━━━━━━━━━━━━━━ accuracy: 0.9902 - loss: 0.0402 - val_accuracy: 0.9831 - val_loss: 0.0584\n",
      "Epoch 1100/2000\n",
      "10/10 ━━━━━━━━━━━━━━━━━━━━ accuracy: 0.9897 - loss: 0.0397 - val_accuracy: 0.9831 - val_loss: 0.0583\n",
      "Epoch 1150/2000\n",
      "10/10 ━━━━━━━━━━━━━━━━━━━━ accuracy: 0.9890 - loss: 0.0401 - val_accuracy: 0.9831 - val_loss: 0.0574\n",
      "Epoch 1200/2000\n",
      "10/10 ━━━━━━━━━━━━━━━━━━━━ accuracy: 0.9910 - loss: 0.0374 - val_accuracy: 0.9838 - val_loss: 0.0598\n",
      "Epoch 1250/2000\n",
      "10/10 ━━━━━━━━━━━━━━━━━━━━ accuracy: 0.9910 - loss: 0.0373 - val_accuracy: 0.9838 - val_loss: 0.0615\n",
      "Epoch 1300/2000\n",
      "10/10 ━━━━━━━━━━━━━━━━━━━━ accuracy: 0.9908 - loss: 0.0377 - val_accuracy: 0.9815 - val_loss: 0.0655\n",
      "Epoch 1350/2000\n",
      "10/10 ━━━━━━━━━━━━━━━━━━━━ accuracy: 0.9900 - loss: 0.0379 - val_accuracy: 0.9846 - val_loss: 0.0644\n",
      "Epoch 1400/2000\n",
      "10/10 ━━━━━━━━━━━━━━━━━━━━ accuracy: 0.9902 - loss: 0.0390 - val_accuracy: 0.9838 - val_loss: 0.0634\n",
      "Epoch 1450/2000\n",
      "10/10 ━━━━━━━━━━━━━━━━━━━━ accuracy: 0.9900 - loss: 0.0371 - val_accuracy: 0.9823 - val_loss: 0.0648\n",
      "Epoch 1500/2000\n",
      "10/10 ━━━━━━━━━━━━━━━━━━━━ accuracy: 0.9913 - loss: 0.0417 - val_accuracy: 0.9831 - val_loss: 0.0556\n",
      "Epoch 1550/2000\n",
      "10/10 ━━━━━━━━━━━━━━━━━━━━ accuracy: 0.9892 - loss: 0.0378 - val_accuracy: 0.9831 - val_loss: 0.0626\n",
      "Epoch 1600/2000\n",
      "10/10 ━━━━━━━━━━━━━━━━━━━━ accuracy: 0.9895 - loss: 0.0413 - val_accuracy: 0.9838 - val_loss: 0.0592\n",
      "Epoch 1650/2000\n",
      "10/10 ━━━━━━━━━━━━━━━━━━━━ accuracy: 0.9854 - loss: 0.0516 - val_accuracy: 0.9823 - val_loss: 0.0602\n",
      "Epoch 1700/2000\n",
      "10/10 ━━━━━━━━━━━━━━━━━━━━ accuracy: 0.9895 - loss: 0.0398 - val_accuracy: 0.9823 - val_loss: 0.0670\n",
      "Epoch 1750/2000\n",
      "10/10 ━━━━━━━━━━━━━━━━━━━━ accuracy: 0.9885 - loss: 0.0420 - val_accuracy: 0.9831 - val_loss: 0.0659\n",
      "Epoch 1800/2000\n",
      "10/10 ━━━━━━━━━━━━━━━━━━━━ accuracy: 0.9910 - loss: 0.0338 - val_accuracy: 0.9838 - val_loss: 0.0679\n",
      "Epoch 1850/2000\n",
      "10/10 ━━━━━━━━━━━━━━━━━━━━ accuracy: 0.9895 - loss: 0.0366 - val_accuracy: 0.9854 - val_loss: 0.0646\n",
      "Epoch 1900/2000\n",
      "10/10 ━━━━━━━━━━━━━━━━━━━━ accuracy: 0.9923 - loss: 0.0321 - val_accuracy: 0.9823 - val_loss: 0.0684\n",
      "Epoch 1950/2000\n",
      "10/10 ━━━━━━━━━━━━━━━━━━━━ accuracy: 0.9913 - loss: 0.0322 - val_accuracy: 0.9838 - val_loss: 0.0695\n",
      "Epoch 2000/2000\n",
      "10/10 ━━━━━━━━━━━━━━━━━━━━ accuracy: 0.9913 - loss: 0.0329 - val_accuracy: 0.9823 - val_loss: 0.0685\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import LambdaCallback\n",
    "import tensorflow as tf\n",
    "\n",
    "# 50번마다 한 번씩 출력하는 콜백 함수\n",
    "def custom_log(epoch, logs):\n",
    "    if (epoch + 1) % 50 == 0:\n",
    "        num_batches = len(X_train) // 500\n",
    "        print(f\"Epoch {epoch+1}/2000\") \n",
    "        tf.print(f\"{num_batches}/{num_batches} ━━━━━━━━━━━━━━━━━━━━ \"\n",
    "                 f\"accuracy: {logs['accuracy']:.4f} - loss: {logs['loss']:.4f} - \"\n",
    "                 f\"val_accuracy: {logs['val_accuracy']:.4f} - val_loss: {logs['val_loss']:.4f}\")\n",
    "show_status = LambdaCallback(on_epoch_end=custom_log)\n",
    "\n",
    "# 그래프 확인을 위한 긴 학습\n",
    "history=model.fit(X_train, y_train, epochs=2000, batch_size=500, validation_split=0.25, verbose=0, callbacks=show_status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "executionInfo": {
     "elapsed": 302,
     "status": "ok",
     "timestamp": 1689665185429,
     "user": {
      "displayName": "junhwa lee",
      "userId": "11332889748979012167"
     },
     "user_tz": -540
    },
    "id": "zjfuqmQi_nG3",
    "outputId": "5e063b00-d7d7-4583-ab63-5d19abbd41a8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.932512</td>\n",
       "      <td>0.193409</td>\n",
       "      <td>0.936154</td>\n",
       "      <td>0.191379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.931229</td>\n",
       "      <td>0.191842</td>\n",
       "      <td>0.936154</td>\n",
       "      <td>0.190144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.932769</td>\n",
       "      <td>0.189938</td>\n",
       "      <td>0.936154</td>\n",
       "      <td>0.188668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.932256</td>\n",
       "      <td>0.188119</td>\n",
       "      <td>0.936154</td>\n",
       "      <td>0.186798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.933025</td>\n",
       "      <td>0.186714</td>\n",
       "      <td>0.935385</td>\n",
       "      <td>0.185376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>0.990506</td>\n",
       "      <td>0.031653</td>\n",
       "      <td>0.983077</td>\n",
       "      <td>0.069656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>0.989992</td>\n",
       "      <td>0.033307</td>\n",
       "      <td>0.982308</td>\n",
       "      <td>0.068762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>0.990762</td>\n",
       "      <td>0.031349</td>\n",
       "      <td>0.982308</td>\n",
       "      <td>0.068466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>0.990249</td>\n",
       "      <td>0.034186</td>\n",
       "      <td>0.982308</td>\n",
       "      <td>0.066601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>0.991275</td>\n",
       "      <td>0.032869</td>\n",
       "      <td>0.982308</td>\n",
       "      <td>0.068530</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      accuracy      loss  val_accuracy  val_loss\n",
       "0     0.932512  0.193409      0.936154  0.191379\n",
       "1     0.931229  0.191842      0.936154  0.190144\n",
       "2     0.932769  0.189938      0.936154  0.188668\n",
       "3     0.932256  0.188119      0.936154  0.186798\n",
       "4     0.933025  0.186714      0.935385  0.185376\n",
       "...        ...       ...           ...       ...\n",
       "1995  0.990506  0.031653      0.983077  0.069656\n",
       "1996  0.989992  0.033307      0.982308  0.068762\n",
       "1997  0.990762  0.031349      0.982308  0.068466\n",
       "1998  0.990249  0.034186      0.982308  0.066601\n",
       "1999  0.991275  0.032869      0.982308  0.068530\n",
       "\n",
       "[2000 rows x 4 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# history에 저장된 학습 결과를 확인해 보겠습니다.\n",
    "hist_df=pd.DataFrame(history.history)\n",
    "hist_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 449
    },
    "executionInfo": {
     "elapsed": 871,
     "status": "ok",
     "timestamp": 1689665189006,
     "user": {
      "displayName": "junhwa lee",
      "userId": "11332889748979012167"
     },
     "user_tz": -540
    },
    "id": "yij0pMOC_nG4",
    "outputId": "f18455a4-99ea-4848-b5dd-517f3d672b6c"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# y_vloss에 테스트셋(여기서는 검증셋)의 오차를 저장합니다.\n",
    "y_vloss=hist_df['val_loss']\n",
    "\n",
    "# y_loss에 학습셋의 오차를 저장합니다.\n",
    "y_loss=hist_df['loss']\n",
    "\n",
    "#x 값을 지정하고 테스트셋(검증셋)의 오차를 빨간색으로, 학습셋의 오차를 파란색으로 표시합니다.\n",
    "x_len = np.arange(len(y_loss))\n",
    "plt.plot(x_len, y_vloss, \"o\", c=\"red\", markersize=2, label='Testset_loss')\n",
    "plt.plot(x_len, y_loss, \"o\", c=\"blue\", markersize=2, label='Trainset_loss')\n",
    "\n",
    "plt.legend(loc='upper right')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qfgIYVvS_nG4"
   },
   "source": [
    "## 4. 학습의 자동 중단"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "35U6o4cH_nG4"
   },
   "source": [
    "### 기본 코드 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 400,
     "status": "ok",
     "timestamp": 1689665204094,
     "user": {
      "displayName": "junhwa lee",
      "userId": "11332889748979012167"
     },
     "user_tz": -540
    },
    "id": "NOyIPFzB_nG5",
    "outputId": "6d4bd773-5eda-4286-fa14-c4290a192873"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">390</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">372</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">104</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │               <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)                  │             \u001b[38;5;34m390\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m)                  │             \u001b[38;5;34m372\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)                   │             \u001b[38;5;34m104\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │               \u001b[38;5;34m9\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">875</span> (3.42 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m875\u001b[0m (3.42 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">875</span> (3.42 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m875\u001b[0m (3.42 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# 와인 데이터를 불러옵니다.\n",
    "df = pd.read_csv('./data/wine.csv', header=None)\n",
    "\n",
    "# 와인의 속성을 X로 와인의 분류를 y로 저장합니다.\n",
    "X = df.iloc[:,0:12]\n",
    "y = df.iloc[:,12]\n",
    "\n",
    "# 학습셋과 테스트셋으로 나눕니다.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True)\n",
    "\n",
    "# 모델 구조를 설정합니다.\n",
    "model = Sequential()\n",
    "model.add(Dense(30,  input_dim=12, activation='relu'))\n",
    "model.add(Dense(12, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.summary()\n",
    "\n",
    "# 모델을 컴파일합니다.\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TVZTtnL4_nG5"
   },
   "source": [
    "### 학습의 자동 중단 및 최적화 모델 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10063,
     "status": "ok",
     "timestamp": 1689665363040,
     "user": {
      "displayName": "junhwa lee",
      "userId": "11332889748979012167"
     },
     "user_tz": -540
    },
    "id": "7EDUE8N5_nG5",
    "outputId": "d498420b-78e5-42b7-a8d2-e63b669b07a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.2466 - loss: 43.8434 - val_accuracy: 0.2500 - val_loss: 38.0598\n",
      "Epoch 2/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.2422 - loss: 36.0106 - val_accuracy: 0.2500 - val_loss: 31.1558\n",
      "Epoch 3/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.2502 - loss: 29.0394 - val_accuracy: 0.2500 - val_loss: 25.2727\n",
      "Epoch 4/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.2406 - loss: 23.8435 - val_accuracy: 0.2500 - val_loss: 20.3037\n",
      "Epoch 5/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.2402 - loss: 19.1805 - val_accuracy: 0.2500 - val_loss: 16.1163\n",
      "Epoch 6/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.2512 - loss: 14.9059 - val_accuracy: 0.2500 - val_loss: 12.4238\n",
      "Epoch 7/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.2482 - loss: 11.3594 - val_accuracy: 0.2500 - val_loss: 8.9799\n",
      "Epoch 8/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.2387 - loss: 8.2100 - val_accuracy: 0.2500 - val_loss: 5.6093\n",
      "Epoch 9/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.2421 - loss: 4.6632 - val_accuracy: 0.2746 - val_loss: 1.8795\n",
      "Epoch 10/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4741 - loss: 1.1851 - val_accuracy: 0.8931 - val_loss: 0.3116\n",
      "Epoch 11/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9076 - loss: 0.2745 - val_accuracy: 0.9131 - val_loss: 0.2495\n",
      "Epoch 12/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9259 - loss: 0.2288 - val_accuracy: 0.9269 - val_loss: 0.2338\n",
      "Epoch 13/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9382 - loss: 0.2031 - val_accuracy: 0.9338 - val_loss: 0.2303\n",
      "Epoch 14/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9397 - loss: 0.2014 - val_accuracy: 0.9369 - val_loss: 0.2228\n",
      "Epoch 15/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9375 - loss: 0.2080 - val_accuracy: 0.9369 - val_loss: 0.2124\n",
      "Epoch 16/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9418 - loss: 0.1932 - val_accuracy: 0.9369 - val_loss: 0.2080\n",
      "Epoch 17/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9424 - loss: 0.1897 - val_accuracy: 0.9369 - val_loss: 0.2021\n",
      "Epoch 18/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9423 - loss: 0.1880 - val_accuracy: 0.9369 - val_loss: 0.1996\n",
      "Epoch 19/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9405 - loss: 0.1851 - val_accuracy: 0.9362 - val_loss: 0.1955\n",
      "Epoch 20/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9481 - loss: 0.1705 - val_accuracy: 0.9362 - val_loss: 0.1944\n",
      "Epoch 21/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9414 - loss: 0.1860 - val_accuracy: 0.9369 - val_loss: 0.1914\n",
      "Epoch 22/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9469 - loss: 0.1716 - val_accuracy: 0.9362 - val_loss: 0.1904\n",
      "Epoch 23/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9464 - loss: 0.1682 - val_accuracy: 0.9362 - val_loss: 0.1883\n",
      "Epoch 24/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9414 - loss: 0.1799 - val_accuracy: 0.9362 - val_loss: 0.1881\n",
      "Epoch 25/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9454 - loss: 0.1721 - val_accuracy: 0.9362 - val_loss: 0.1863\n",
      "Epoch 26/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9448 - loss: 0.1669 - val_accuracy: 0.9377 - val_loss: 0.1852\n",
      "Epoch 27/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9432 - loss: 0.1733 - val_accuracy: 0.9392 - val_loss: 0.1840\n",
      "Epoch 28/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9458 - loss: 0.1674 - val_accuracy: 0.9392 - val_loss: 0.1832\n",
      "Epoch 29/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9470 - loss: 0.1715 - val_accuracy: 0.9392 - val_loss: 0.1821\n",
      "Epoch 30/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9464 - loss: 0.1634 - val_accuracy: 0.9392 - val_loss: 0.1816\n",
      "Epoch 31/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9461 - loss: 0.1650 - val_accuracy: 0.9392 - val_loss: 0.1798\n",
      "Epoch 32/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9470 - loss: 0.1700 - val_accuracy: 0.9392 - val_loss: 0.1799\n",
      "Epoch 33/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9451 - loss: 0.1651 - val_accuracy: 0.9392 - val_loss: 0.1779\n",
      "Epoch 34/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9502 - loss: 0.1597 - val_accuracy: 0.9392 - val_loss: 0.1779\n",
      "Epoch 35/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9475 - loss: 0.1616 - val_accuracy: 0.9400 - val_loss: 0.1763\n",
      "Epoch 36/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9478 - loss: 0.1595 - val_accuracy: 0.9392 - val_loss: 0.1759\n",
      "Epoch 37/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9471 - loss: 0.1598 - val_accuracy: 0.9392 - val_loss: 0.1746\n",
      "Epoch 38/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9503 - loss: 0.1549 - val_accuracy: 0.9408 - val_loss: 0.1740\n",
      "Epoch 39/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9453 - loss: 0.1626 - val_accuracy: 0.9408 - val_loss: 0.1733\n",
      "Epoch 40/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9495 - loss: 0.1578 - val_accuracy: 0.9408 - val_loss: 0.1723\n",
      "Epoch 41/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9521 - loss: 0.1451 - val_accuracy: 0.9415 - val_loss: 0.1713\n",
      "Epoch 42/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9521 - loss: 0.1533 - val_accuracy: 0.9415 - val_loss: 0.1703\n",
      "Epoch 43/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9526 - loss: 0.1551 - val_accuracy: 0.9423 - val_loss: 0.1697\n",
      "Epoch 44/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9470 - loss: 0.1608 - val_accuracy: 0.9423 - val_loss: 0.1682\n",
      "Epoch 45/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9513 - loss: 0.1486 - val_accuracy: 0.9423 - val_loss: 0.1676\n",
      "Epoch 46/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9536 - loss: 0.1414 - val_accuracy: 0.9423 - val_loss: 0.1665\n",
      "Epoch 47/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9506 - loss: 0.1515 - val_accuracy: 0.9446 - val_loss: 0.1652\n",
      "Epoch 48/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9515 - loss: 0.1503 - val_accuracy: 0.9454 - val_loss: 0.1639\n",
      "Epoch 49/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9523 - loss: 0.1453 - val_accuracy: 0.9454 - val_loss: 0.1631\n",
      "Epoch 50/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9489 - loss: 0.1527 - val_accuracy: 0.9454 - val_loss: 0.1622\n",
      "Epoch 51/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9527 - loss: 0.1459 - val_accuracy: 0.9438 - val_loss: 0.1617\n",
      "Epoch 52/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9554 - loss: 0.1425 - val_accuracy: 0.9462 - val_loss: 0.1598\n",
      "Epoch 53/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9526 - loss: 0.1440 - val_accuracy: 0.9454 - val_loss: 0.1597\n",
      "Epoch 54/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9566 - loss: 0.1356 - val_accuracy: 0.9462 - val_loss: 0.1581\n",
      "Epoch 55/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9464 - loss: 0.1574 - val_accuracy: 0.9454 - val_loss: 0.1578\n",
      "Epoch 56/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9527 - loss: 0.1450 - val_accuracy: 0.9462 - val_loss: 0.1557\n",
      "Epoch 57/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9550 - loss: 0.1384 - val_accuracy: 0.9462 - val_loss: 0.1549\n",
      "Epoch 58/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9532 - loss: 0.1387 - val_accuracy: 0.9469 - val_loss: 0.1542\n",
      "Epoch 59/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9557 - loss: 0.1391 - val_accuracy: 0.9492 - val_loss: 0.1528\n",
      "Epoch 60/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9515 - loss: 0.1460 - val_accuracy: 0.9469 - val_loss: 0.1525\n",
      "Epoch 61/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9545 - loss: 0.1368 - val_accuracy: 0.9485 - val_loss: 0.1489\n",
      "Epoch 62/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9555 - loss: 0.1364 - val_accuracy: 0.9500 - val_loss: 0.1491\n",
      "Epoch 63/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9560 - loss: 0.1388 - val_accuracy: 0.9492 - val_loss: 0.1445\n",
      "Epoch 64/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9545 - loss: 0.1374 - val_accuracy: 0.9508 - val_loss: 0.1446\n",
      "Epoch 65/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9564 - loss: 0.1331 - val_accuracy: 0.9508 - val_loss: 0.1421\n",
      "Epoch 66/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9560 - loss: 0.1284 - val_accuracy: 0.9492 - val_loss: 0.1395\n",
      "Epoch 67/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9557 - loss: 0.1310 - val_accuracy: 0.9500 - val_loss: 0.1387\n",
      "Epoch 68/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9568 - loss: 0.1317 - val_accuracy: 0.9508 - val_loss: 0.1378\n",
      "Epoch 69/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9547 - loss: 0.1345 - val_accuracy: 0.9508 - val_loss: 0.1384\n",
      "Epoch 70/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9535 - loss: 0.1302 - val_accuracy: 0.9508 - val_loss: 0.1341\n",
      "Epoch 71/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9599 - loss: 0.1250 - val_accuracy: 0.9500 - val_loss: 0.1362\n",
      "Epoch 72/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9537 - loss: 0.1294 - val_accuracy: 0.9508 - val_loss: 0.1316\n",
      "Epoch 73/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9563 - loss: 0.1293 - val_accuracy: 0.9508 - val_loss: 0.1326\n",
      "Epoch 74/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9575 - loss: 0.1246 - val_accuracy: 0.9531 - val_loss: 0.1295\n",
      "Epoch 75/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9578 - loss: 0.1216 - val_accuracy: 0.9500 - val_loss: 0.1307\n",
      "Epoch 76/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9560 - loss: 0.1227 - val_accuracy: 0.9500 - val_loss: 0.1288\n",
      "Epoch 77/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9579 - loss: 0.1179 - val_accuracy: 0.9500 - val_loss: 0.1278\n",
      "Epoch 78/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9594 - loss: 0.1108 - val_accuracy: 0.9508 - val_loss: 0.1264\n",
      "Epoch 79/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9566 - loss: 0.1189 - val_accuracy: 0.9492 - val_loss: 0.1263\n",
      "Epoch 80/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9558 - loss: 0.1204 - val_accuracy: 0.9508 - val_loss: 0.1242\n",
      "Epoch 81/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9586 - loss: 0.1200 - val_accuracy: 0.9492 - val_loss: 0.1258\n",
      "Epoch 82/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9593 - loss: 0.1113 - val_accuracy: 0.9538 - val_loss: 0.1222\n",
      "Epoch 83/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9561 - loss: 0.1201 - val_accuracy: 0.9492 - val_loss: 0.1299\n",
      "Epoch 84/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9589 - loss: 0.1189 - val_accuracy: 0.9508 - val_loss: 0.1203\n",
      "Epoch 85/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9631 - loss: 0.1155 - val_accuracy: 0.9492 - val_loss: 0.1257\n",
      "Epoch 86/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9617 - loss: 0.1070 - val_accuracy: 0.9508 - val_loss: 0.1183\n",
      "Epoch 87/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9645 - loss: 0.1084 - val_accuracy: 0.9500 - val_loss: 0.1203\n",
      "Epoch 88/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9617 - loss: 0.1144 - val_accuracy: 0.9523 - val_loss: 0.1180\n",
      "Epoch 89/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9603 - loss: 0.1076 - val_accuracy: 0.9515 - val_loss: 0.1172\n",
      "Epoch 90/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9602 - loss: 0.1096 - val_accuracy: 0.9500 - val_loss: 0.1188\n",
      "Epoch 91/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9639 - loss: 0.1067 - val_accuracy: 0.9562 - val_loss: 0.1144\n",
      "Epoch 92/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9654 - loss: 0.1060 - val_accuracy: 0.9515 - val_loss: 0.1157\n",
      "Epoch 93/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9666 - loss: 0.0981 - val_accuracy: 0.9531 - val_loss: 0.1137\n",
      "Epoch 94/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9593 - loss: 0.1137 - val_accuracy: 0.9538 - val_loss: 0.1138\n",
      "Epoch 95/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9636 - loss: 0.1010 - val_accuracy: 0.9562 - val_loss: 0.1114\n",
      "Epoch 96/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9601 - loss: 0.1004 - val_accuracy: 0.9523 - val_loss: 0.1124\n",
      "Epoch 97/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9650 - loss: 0.1013 - val_accuracy: 0.9531 - val_loss: 0.1123\n",
      "Epoch 98/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9665 - loss: 0.0941 - val_accuracy: 0.9608 - val_loss: 0.1094\n",
      "Epoch 99/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9651 - loss: 0.1029 - val_accuracy: 0.9554 - val_loss: 0.1112\n",
      "Epoch 100/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9647 - loss: 0.1015 - val_accuracy: 0.9546 - val_loss: 0.1091\n",
      "Epoch 101/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9666 - loss: 0.0911 - val_accuracy: 0.9600 - val_loss: 0.1070\n",
      "Epoch 102/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9670 - loss: 0.0972 - val_accuracy: 0.9600 - val_loss: 0.1074\n",
      "Epoch 103/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9662 - loss: 0.0989 - val_accuracy: 0.9631 - val_loss: 0.1055\n",
      "Epoch 104/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9679 - loss: 0.0991 - val_accuracy: 0.9562 - val_loss: 0.1089\n",
      "Epoch 105/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9651 - loss: 0.0984 - val_accuracy: 0.9646 - val_loss: 0.1042\n",
      "Epoch 106/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9690 - loss: 0.1005 - val_accuracy: 0.9538 - val_loss: 0.1095\n",
      "Epoch 107/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9662 - loss: 0.0975 - val_accuracy: 0.9669 - val_loss: 0.1029\n",
      "Epoch 108/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9680 - loss: 0.1012 - val_accuracy: 0.9569 - val_loss: 0.1058\n",
      "Epoch 109/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9703 - loss: 0.0882 - val_accuracy: 0.9608 - val_loss: 0.1038\n",
      "Epoch 110/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9650 - loss: 0.1023 - val_accuracy: 0.9638 - val_loss: 0.1015\n",
      "Epoch 111/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9678 - loss: 0.0907 - val_accuracy: 0.9700 - val_loss: 0.1004\n",
      "Epoch 112/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9706 - loss: 0.0956 - val_accuracy: 0.9546 - val_loss: 0.1056\n",
      "Epoch 113/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9682 - loss: 0.0878 - val_accuracy: 0.9677 - val_loss: 0.0992\n",
      "Epoch 114/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9684 - loss: 0.0922 - val_accuracy: 0.9677 - val_loss: 0.0990\n",
      "Epoch 115/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9703 - loss: 0.0893 - val_accuracy: 0.9677 - val_loss: 0.0986\n",
      "Epoch 116/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9697 - loss: 0.0903 - val_accuracy: 0.9662 - val_loss: 0.0982\n",
      "Epoch 117/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9702 - loss: 0.0984 - val_accuracy: 0.9669 - val_loss: 0.0988\n",
      "Epoch 118/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9703 - loss: 0.0858 - val_accuracy: 0.9723 - val_loss: 0.0958\n",
      "Epoch 119/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9685 - loss: 0.0934 - val_accuracy: 0.9577 - val_loss: 0.1027\n",
      "Epoch 120/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9692 - loss: 0.0908 - val_accuracy: 0.9746 - val_loss: 0.0952\n",
      "Epoch 121/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9702 - loss: 0.0911 - val_accuracy: 0.9669 - val_loss: 0.0973\n",
      "Epoch 122/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9728 - loss: 0.0878 - val_accuracy: 0.9700 - val_loss: 0.0957\n",
      "Epoch 123/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9685 - loss: 0.0919 - val_accuracy: 0.9700 - val_loss: 0.0938\n",
      "Epoch 124/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9710 - loss: 0.0840 - val_accuracy: 0.9731 - val_loss: 0.0931\n",
      "Epoch 125/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9741 - loss: 0.0851 - val_accuracy: 0.9692 - val_loss: 0.0947\n",
      "Epoch 126/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9727 - loss: 0.0822 - val_accuracy: 0.9731 - val_loss: 0.0920\n",
      "Epoch 127/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9721 - loss: 0.0845 - val_accuracy: 0.9700 - val_loss: 0.0925\n",
      "Epoch 128/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9735 - loss: 0.0819 - val_accuracy: 0.9738 - val_loss: 0.0914\n",
      "Epoch 129/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9719 - loss: 0.0827 - val_accuracy: 0.9662 - val_loss: 0.0948\n",
      "Epoch 130/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9714 - loss: 0.0842 - val_accuracy: 0.9754 - val_loss: 0.0904\n",
      "Epoch 131/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9737 - loss: 0.0817 - val_accuracy: 0.9754 - val_loss: 0.0901\n",
      "Epoch 132/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9746 - loss: 0.0889 - val_accuracy: 0.9685 - val_loss: 0.0933\n",
      "Epoch 133/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9717 - loss: 0.0842 - val_accuracy: 0.9762 - val_loss: 0.0887\n",
      "Epoch 134/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9727 - loss: 0.0914 - val_accuracy: 0.9723 - val_loss: 0.0903\n",
      "Epoch 135/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9747 - loss: 0.0896 - val_accuracy: 0.9746 - val_loss: 0.0893\n",
      "Epoch 136/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9723 - loss: 0.0888 - val_accuracy: 0.9738 - val_loss: 0.0872\n",
      "Epoch 137/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9747 - loss: 0.0813 - val_accuracy: 0.9754 - val_loss: 0.0873\n",
      "Epoch 138/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9732 - loss: 0.0768 - val_accuracy: 0.9777 - val_loss: 0.0863\n",
      "Epoch 139/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9742 - loss: 0.0842 - val_accuracy: 0.9662 - val_loss: 0.0926\n",
      "Epoch 140/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9735 - loss: 0.0753 - val_accuracy: 0.9777 - val_loss: 0.0871\n",
      "Epoch 141/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9747 - loss: 0.0842 - val_accuracy: 0.9754 - val_loss: 0.0877\n",
      "Epoch 142/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9742 - loss: 0.0787 - val_accuracy: 0.9754 - val_loss: 0.0853\n",
      "Epoch 143/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9756 - loss: 0.0803 - val_accuracy: 0.9762 - val_loss: 0.0855\n",
      "Epoch 144/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9754 - loss: 0.0792 - val_accuracy: 0.9754 - val_loss: 0.0840\n",
      "Epoch 145/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9766 - loss: 0.0784 - val_accuracy: 0.9762 - val_loss: 0.0841\n",
      "Epoch 146/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9774 - loss: 0.0734 - val_accuracy: 0.9762 - val_loss: 0.0836\n",
      "Epoch 147/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9732 - loss: 0.0802 - val_accuracy: 0.9777 - val_loss: 0.0830\n",
      "Epoch 148/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9780 - loss: 0.0784 - val_accuracy: 0.9762 - val_loss: 0.0848\n",
      "Epoch 149/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9766 - loss: 0.0692 - val_accuracy: 0.9777 - val_loss: 0.0818\n",
      "Epoch 150/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9717 - loss: 0.0761 - val_accuracy: 0.9762 - val_loss: 0.0835\n",
      "Epoch 151/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9760 - loss: 0.0759 - val_accuracy: 0.9762 - val_loss: 0.0847\n",
      "Epoch 152/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9771 - loss: 0.0683 - val_accuracy: 0.9785 - val_loss: 0.0809\n",
      "Epoch 153/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9804 - loss: 0.0684 - val_accuracy: 0.9777 - val_loss: 0.0807\n",
      "Epoch 154/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9738 - loss: 0.0776 - val_accuracy: 0.9785 - val_loss: 0.0810\n",
      "Epoch 155/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9765 - loss: 0.0785 - val_accuracy: 0.9762 - val_loss: 0.0833\n",
      "Epoch 156/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9748 - loss: 0.0789 - val_accuracy: 0.9762 - val_loss: 0.0813\n",
      "Epoch 157/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9765 - loss: 0.0663 - val_accuracy: 0.9792 - val_loss: 0.0794\n",
      "Epoch 158/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9795 - loss: 0.0706 - val_accuracy: 0.9769 - val_loss: 0.0804\n",
      "Epoch 159/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9768 - loss: 0.0716 - val_accuracy: 0.9785 - val_loss: 0.0790\n",
      "Epoch 160/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9817 - loss: 0.0644 - val_accuracy: 0.9777 - val_loss: 0.0788\n",
      "Epoch 161/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9778 - loss: 0.0730 - val_accuracy: 0.9785 - val_loss: 0.0785\n",
      "Epoch 162/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9774 - loss: 0.0730 - val_accuracy: 0.9785 - val_loss: 0.0780\n",
      "Epoch 163/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9779 - loss: 0.0704 - val_accuracy: 0.9785 - val_loss: 0.0778\n",
      "Epoch 164/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9786 - loss: 0.0709 - val_accuracy: 0.9792 - val_loss: 0.0773\n",
      "Epoch 165/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9804 - loss: 0.0672 - val_accuracy: 0.9785 - val_loss: 0.0770\n",
      "Epoch 166/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9798 - loss: 0.0671 - val_accuracy: 0.9785 - val_loss: 0.0770\n",
      "Epoch 167/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9786 - loss: 0.0752 - val_accuracy: 0.9769 - val_loss: 0.0817\n",
      "Epoch 168/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9772 - loss: 0.0711 - val_accuracy: 0.9785 - val_loss: 0.0756\n",
      "Epoch 169/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9816 - loss: 0.0648 - val_accuracy: 0.9785 - val_loss: 0.0753\n",
      "Epoch 170/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9776 - loss: 0.0758 - val_accuracy: 0.9777 - val_loss: 0.0807\n",
      "Epoch 171/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9781 - loss: 0.0674 - val_accuracy: 0.9785 - val_loss: 0.0748\n",
      "Epoch 172/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9814 - loss: 0.0668 - val_accuracy: 0.9792 - val_loss: 0.0743\n",
      "Epoch 173/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9808 - loss: 0.0684 - val_accuracy: 0.9785 - val_loss: 0.0747\n",
      "Epoch 174/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9788 - loss: 0.0683 - val_accuracy: 0.9792 - val_loss: 0.0736\n",
      "Epoch 175/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9784 - loss: 0.0666 - val_accuracy: 0.9785 - val_loss: 0.0740\n",
      "Epoch 176/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9789 - loss: 0.0638 - val_accuracy: 0.9792 - val_loss: 0.0729\n",
      "Epoch 177/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9807 - loss: 0.0600 - val_accuracy: 0.9792 - val_loss: 0.0732\n",
      "Epoch 178/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9815 - loss: 0.0686 - val_accuracy: 0.9792 - val_loss: 0.0733\n",
      "Epoch 179/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9782 - loss: 0.0683 - val_accuracy: 0.9785 - val_loss: 0.0750\n",
      "Epoch 180/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9813 - loss: 0.0684 - val_accuracy: 0.9792 - val_loss: 0.0733\n",
      "Epoch 181/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9805 - loss: 0.0603 - val_accuracy: 0.9808 - val_loss: 0.0721\n",
      "Epoch 182/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9807 - loss: 0.0633 - val_accuracy: 0.9792 - val_loss: 0.0728\n",
      "Epoch 183/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9804 - loss: 0.0637 - val_accuracy: 0.9800 - val_loss: 0.0727\n",
      "Epoch 184/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9804 - loss: 0.0637 - val_accuracy: 0.9792 - val_loss: 0.0722\n",
      "Epoch 185/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9772 - loss: 0.0717 - val_accuracy: 0.9800 - val_loss: 0.0709\n",
      "Epoch 186/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9822 - loss: 0.0594 - val_accuracy: 0.9800 - val_loss: 0.0704\n",
      "Epoch 187/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9820 - loss: 0.0621 - val_accuracy: 0.9808 - val_loss: 0.0699\n",
      "Epoch 188/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9803 - loss: 0.0686 - val_accuracy: 0.9808 - val_loss: 0.0699\n",
      "Epoch 189/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9813 - loss: 0.0632 - val_accuracy: 0.9800 - val_loss: 0.0713\n",
      "Epoch 190/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9789 - loss: 0.0702 - val_accuracy: 0.9792 - val_loss: 0.0712\n",
      "Epoch 191/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9796 - loss: 0.0606 - val_accuracy: 0.9815 - val_loss: 0.0690\n",
      "Epoch 192/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9837 - loss: 0.0581 - val_accuracy: 0.9808 - val_loss: 0.0687\n",
      "Epoch 193/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9840 - loss: 0.0613 - val_accuracy: 0.9785 - val_loss: 0.0719\n",
      "Epoch 194/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9822 - loss: 0.0589 - val_accuracy: 0.9808 - val_loss: 0.0680\n",
      "Epoch 195/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9811 - loss: 0.0649 - val_accuracy: 0.9808 - val_loss: 0.0681\n",
      "Epoch 196/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9832 - loss: 0.0563 - val_accuracy: 0.9808 - val_loss: 0.0681\n",
      "Epoch 197/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9827 - loss: 0.0577 - val_accuracy: 0.9808 - val_loss: 0.0678\n",
      "Epoch 198/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9809 - loss: 0.0586 - val_accuracy: 0.9808 - val_loss: 0.0681\n",
      "Epoch 199/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9833 - loss: 0.0545 - val_accuracy: 0.9808 - val_loss: 0.0666\n",
      "Epoch 200/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9800 - loss: 0.0668 - val_accuracy: 0.9808 - val_loss: 0.0678\n",
      "Epoch 201/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9831 - loss: 0.0589 - val_accuracy: 0.9808 - val_loss: 0.0691\n",
      "Epoch 202/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9778 - loss: 0.0712 - val_accuracy: 0.9800 - val_loss: 0.0684\n",
      "Epoch 203/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9804 - loss: 0.0612 - val_accuracy: 0.9808 - val_loss: 0.0659\n",
      "Epoch 204/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9791 - loss: 0.0654 - val_accuracy: 0.9808 - val_loss: 0.0666\n",
      "Epoch 205/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9796 - loss: 0.0684 - val_accuracy: 0.9800 - val_loss: 0.0677\n",
      "Epoch 206/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9806 - loss: 0.0602 - val_accuracy: 0.9808 - val_loss: 0.0652\n",
      "Epoch 207/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9821 - loss: 0.0568 - val_accuracy: 0.9800 - val_loss: 0.0682\n",
      "Epoch 208/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9799 - loss: 0.0604 - val_accuracy: 0.9785 - val_loss: 0.0697\n",
      "Epoch 209/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9798 - loss: 0.0667 - val_accuracy: 0.9808 - val_loss: 0.0648\n",
      "Epoch 210/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9829 - loss: 0.0560 - val_accuracy: 0.9808 - val_loss: 0.0653\n",
      "Epoch 211/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9807 - loss: 0.0611 - val_accuracy: 0.9808 - val_loss: 0.0679\n",
      "Epoch 212/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9813 - loss: 0.0574 - val_accuracy: 0.9808 - val_loss: 0.0645\n",
      "Epoch 213/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9818 - loss: 0.0580 - val_accuracy: 0.9815 - val_loss: 0.0635\n",
      "Epoch 214/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9806 - loss: 0.0630 - val_accuracy: 0.9808 - val_loss: 0.0650\n",
      "Epoch 215/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9811 - loss: 0.0624 - val_accuracy: 0.9815 - val_loss: 0.0670\n",
      "Epoch 216/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9822 - loss: 0.0579 - val_accuracy: 0.9808 - val_loss: 0.0637\n",
      "Epoch 217/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9847 - loss: 0.0542 - val_accuracy: 0.9815 - val_loss: 0.0629\n",
      "Epoch 218/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9827 - loss: 0.0603 - val_accuracy: 0.9808 - val_loss: 0.0639\n",
      "Epoch 219/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9830 - loss: 0.0584 - val_accuracy: 0.9808 - val_loss: 0.0640\n",
      "Epoch 220/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9821 - loss: 0.0574 - val_accuracy: 0.9808 - val_loss: 0.0633\n",
      "Epoch 221/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9826 - loss: 0.0676 - val_accuracy: 0.9808 - val_loss: 0.0635\n",
      "Epoch 222/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9811 - loss: 0.0538 - val_accuracy: 0.9808 - val_loss: 0.0629\n",
      "Epoch 223/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9831 - loss: 0.0561 - val_accuracy: 0.9808 - val_loss: 0.0633\n",
      "Epoch 224/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9815 - loss: 0.0579 - val_accuracy: 0.9800 - val_loss: 0.0619\n",
      "Epoch 225/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9821 - loss: 0.0593 - val_accuracy: 0.9800 - val_loss: 0.0655\n",
      "Epoch 226/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9830 - loss: 0.0571 - val_accuracy: 0.9815 - val_loss: 0.0614\n",
      "Epoch 227/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9815 - loss: 0.0592 - val_accuracy: 0.9823 - val_loss: 0.0641\n",
      "Epoch 228/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9839 - loss: 0.0537 - val_accuracy: 0.9823 - val_loss: 0.0610\n",
      "Epoch 229/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9816 - loss: 0.0621 - val_accuracy: 0.9800 - val_loss: 0.0615\n",
      "Epoch 230/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9818 - loss: 0.0594 - val_accuracy: 0.9785 - val_loss: 0.0656\n",
      "Epoch 231/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9814 - loss: 0.0590 - val_accuracy: 0.9808 - val_loss: 0.0606\n",
      "Epoch 232/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9858 - loss: 0.0541 - val_accuracy: 0.9800 - val_loss: 0.0616\n",
      "Epoch 233/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9819 - loss: 0.0617 - val_accuracy: 0.9800 - val_loss: 0.0611\n",
      "Epoch 234/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9834 - loss: 0.0536 - val_accuracy: 0.9815 - val_loss: 0.0601\n",
      "Epoch 235/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9848 - loss: 0.0546 - val_accuracy: 0.9815 - val_loss: 0.0621\n",
      "Epoch 236/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9803 - loss: 0.0612 - val_accuracy: 0.9792 - val_loss: 0.0650\n",
      "Epoch 237/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9814 - loss: 0.0535 - val_accuracy: 0.9815 - val_loss: 0.0595\n",
      "Epoch 238/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9833 - loss: 0.0525 - val_accuracy: 0.9808 - val_loss: 0.0601\n",
      "Epoch 239/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9856 - loss: 0.0538 - val_accuracy: 0.9815 - val_loss: 0.0634\n",
      "Epoch 240/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9845 - loss: 0.0472 - val_accuracy: 0.9808 - val_loss: 0.0595\n",
      "Epoch 241/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9824 - loss: 0.0542 - val_accuracy: 0.9808 - val_loss: 0.0594\n",
      "Epoch 242/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9819 - loss: 0.0634 - val_accuracy: 0.9808 - val_loss: 0.0594\n",
      "Epoch 243/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9838 - loss: 0.0591 - val_accuracy: 0.9808 - val_loss: 0.0594\n",
      "Epoch 244/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9805 - loss: 0.0608 - val_accuracy: 0.9808 - val_loss: 0.0634\n",
      "Epoch 245/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9831 - loss: 0.0594 - val_accuracy: 0.9808 - val_loss: 0.0591\n",
      "Epoch 246/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9827 - loss: 0.0575 - val_accuracy: 0.9808 - val_loss: 0.0595\n",
      "Epoch 247/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9840 - loss: 0.0505 - val_accuracy: 0.9808 - val_loss: 0.0593\n",
      "Epoch 248/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9844 - loss: 0.0569 - val_accuracy: 0.9800 - val_loss: 0.0587\n",
      "Epoch 249/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9874 - loss: 0.0477 - val_accuracy: 0.9808 - val_loss: 0.0588\n",
      "Epoch 250/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9823 - loss: 0.0566 - val_accuracy: 0.9815 - val_loss: 0.0601\n",
      "Epoch 251/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9859 - loss: 0.0538 - val_accuracy: 0.9808 - val_loss: 0.0586\n",
      "Epoch 252/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9849 - loss: 0.0508 - val_accuracy: 0.9815 - val_loss: 0.0588\n",
      "Epoch 253/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9866 - loss: 0.0532 - val_accuracy: 0.9792 - val_loss: 0.0626\n",
      "Epoch 254/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9854 - loss: 0.0530 - val_accuracy: 0.9800 - val_loss: 0.0628\n",
      "Epoch 255/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9842 - loss: 0.0537 - val_accuracy: 0.9808 - val_loss: 0.0591\n",
      "Epoch 256/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9802 - loss: 0.0607 - val_accuracy: 0.9815 - val_loss: 0.0614\n",
      "Epoch 257/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9854 - loss: 0.0519 - val_accuracy: 0.9808 - val_loss: 0.0588\n",
      "Epoch 258/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9822 - loss: 0.0646 - val_accuracy: 0.9815 - val_loss: 0.0613\n",
      "Epoch 259/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9880 - loss: 0.0436 - val_accuracy: 0.9808 - val_loss: 0.0570\n",
      "Epoch 260/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9845 - loss: 0.0534 - val_accuracy: 0.9815 - val_loss: 0.0571\n",
      "Epoch 261/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9825 - loss: 0.0569 - val_accuracy: 0.9800 - val_loss: 0.0634\n",
      "Epoch 262/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9829 - loss: 0.0553 - val_accuracy: 0.9808 - val_loss: 0.0577\n",
      "Epoch 263/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9844 - loss: 0.0547 - val_accuracy: 0.9808 - val_loss: 0.0621\n",
      "Epoch 264/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9830 - loss: 0.0556 - val_accuracy: 0.9808 - val_loss: 0.0578\n",
      "Epoch 265/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9865 - loss: 0.0568 - val_accuracy: 0.9808 - val_loss: 0.0566\n",
      "Epoch 266/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9858 - loss: 0.0500 - val_accuracy: 0.9815 - val_loss: 0.0574\n",
      "Epoch 267/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9846 - loss: 0.0586 - val_accuracy: 0.9808 - val_loss: 0.0623\n",
      "Epoch 268/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9851 - loss: 0.0544 - val_accuracy: 0.9808 - val_loss: 0.0625\n",
      "Epoch 269/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9815 - loss: 0.0569 - val_accuracy: 0.9823 - val_loss: 0.0567\n",
      "Epoch 270/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9829 - loss: 0.0597 - val_accuracy: 0.9831 - val_loss: 0.0599\n",
      "Epoch 271/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9828 - loss: 0.0539 - val_accuracy: 0.9808 - val_loss: 0.0578\n",
      "Epoch 272/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9863 - loss: 0.0516 - val_accuracy: 0.9808 - val_loss: 0.0566\n",
      "Epoch 273/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9880 - loss: 0.0524 - val_accuracy: 0.9815 - val_loss: 0.0587\n",
      "Epoch 274/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9851 - loss: 0.0547 - val_accuracy: 0.9823 - val_loss: 0.0591\n",
      "Epoch 275/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9827 - loss: 0.0581 - val_accuracy: 0.9815 - val_loss: 0.0585\n",
      "Epoch 276/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9855 - loss: 0.0505 - val_accuracy: 0.9808 - val_loss: 0.0566\n",
      "Epoch 277/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9858 - loss: 0.0488 - val_accuracy: 0.9800 - val_loss: 0.0566\n",
      "Epoch 278/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9863 - loss: 0.0512 - val_accuracy: 0.9808 - val_loss: 0.0572\n",
      "Epoch 279/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9857 - loss: 0.0501 - val_accuracy: 0.9823 - val_loss: 0.0580\n",
      "Epoch 280/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9855 - loss: 0.0544 - val_accuracy: 0.9831 - val_loss: 0.0588\n",
      "Epoch 281/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9880 - loss: 0.0497 - val_accuracy: 0.9808 - val_loss: 0.0563\n",
      "Epoch 282/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9859 - loss: 0.0540 - val_accuracy: 0.9808 - val_loss: 0.0569\n",
      "Epoch 283/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9869 - loss: 0.0486 - val_accuracy: 0.9823 - val_loss: 0.0605\n",
      "Epoch 284/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9866 - loss: 0.0447 - val_accuracy: 0.9823 - val_loss: 0.0559\n",
      "Epoch 285/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9863 - loss: 0.0528 - val_accuracy: 0.9808 - val_loss: 0.0577\n",
      "Epoch 286/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9858 - loss: 0.0570 - val_accuracy: 0.9808 - val_loss: 0.0573\n",
      "Epoch 287/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9876 - loss: 0.0456 - val_accuracy: 0.9808 - val_loss: 0.0569\n",
      "Epoch 288/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9835 - loss: 0.0571 - val_accuracy: 0.9815 - val_loss: 0.0578\n",
      "Epoch 289/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9863 - loss: 0.0475 - val_accuracy: 0.9823 - val_loss: 0.0568\n",
      "Epoch 290/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9880 - loss: 0.0485 - val_accuracy: 0.9815 - val_loss: 0.0574\n",
      "Epoch 291/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9851 - loss: 0.0472 - val_accuracy: 0.9823 - val_loss: 0.0595\n",
      "Epoch 292/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9835 - loss: 0.0530 - val_accuracy: 0.9831 - val_loss: 0.0585\n",
      "Epoch 293/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9832 - loss: 0.0620 - val_accuracy: 0.9823 - val_loss: 0.0590\n",
      "Epoch 294/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9857 - loss: 0.0486 - val_accuracy: 0.9831 - val_loss: 0.0560\n",
      "Epoch 295/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9850 - loss: 0.0499 - val_accuracy: 0.9823 - val_loss: 0.0563\n",
      "Epoch 296/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9873 - loss: 0.0502 - val_accuracy: 0.9815 - val_loss: 0.0565\n",
      "Epoch 297/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9878 - loss: 0.0461 - val_accuracy: 0.9815 - val_loss: 0.0561\n",
      "Epoch 298/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9838 - loss: 0.0545 - val_accuracy: 0.9823 - val_loss: 0.0597\n",
      "Epoch 299/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9875 - loss: 0.0427 - val_accuracy: 0.9831 - val_loss: 0.0559\n",
      "Epoch 300/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9847 - loss: 0.0511 - val_accuracy: 0.9815 - val_loss: 0.0564\n",
      "Epoch 301/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9837 - loss: 0.0546 - val_accuracy: 0.9792 - val_loss: 0.0644\n",
      "Epoch 302/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9852 - loss: 0.0505 - val_accuracy: 0.9838 - val_loss: 0.0557\n",
      "Epoch 303/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9861 - loss: 0.0522 - val_accuracy: 0.9823 - val_loss: 0.0557\n",
      "Epoch 304/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9855 - loss: 0.0498 - val_accuracy: 0.9815 - val_loss: 0.0560\n",
      "Epoch 305/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9852 - loss: 0.0539 - val_accuracy: 0.9823 - val_loss: 0.0608\n",
      "Epoch 306/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9857 - loss: 0.0469 - val_accuracy: 0.9831 - val_loss: 0.0556\n",
      "Epoch 307/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9880 - loss: 0.0451 - val_accuracy: 0.9831 - val_loss: 0.0586\n",
      "Epoch 308/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9888 - loss: 0.0453 - val_accuracy: 0.9823 - val_loss: 0.0558\n",
      "Epoch 309/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9828 - loss: 0.0578 - val_accuracy: 0.9823 - val_loss: 0.0564\n",
      "Epoch 310/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9863 - loss: 0.0492 - val_accuracy: 0.9823 - val_loss: 0.0593\n",
      "Epoch 311/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9866 - loss: 0.0500 - val_accuracy: 0.9823 - val_loss: 0.0594\n",
      "Epoch 312/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9858 - loss: 0.0500 - val_accuracy: 0.9823 - val_loss: 0.0565\n",
      "Epoch 313/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9846 - loss: 0.0545 - val_accuracy: 0.9823 - val_loss: 0.0565\n",
      "Epoch 314/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9865 - loss: 0.0498 - val_accuracy: 0.9823 - val_loss: 0.0594\n",
      "Epoch 315/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9853 - loss: 0.0546 - val_accuracy: 0.9831 - val_loss: 0.0591\n",
      "Epoch 316/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9879 - loss: 0.0476 - val_accuracy: 0.9831 - val_loss: 0.0563\n",
      "Epoch 317/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9861 - loss: 0.0479 - val_accuracy: 0.9838 - val_loss: 0.0579\n",
      "Epoch 318/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9866 - loss: 0.0579 - val_accuracy: 0.9785 - val_loss: 0.0742\n",
      "Epoch 319/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9834 - loss: 0.0537 - val_accuracy: 0.9831 - val_loss: 0.0563\n",
      "Epoch 320/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9889 - loss: 0.0462 - val_accuracy: 0.9831 - val_loss: 0.0566\n",
      "Epoch 321/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9849 - loss: 0.0532 - val_accuracy: 0.9792 - val_loss: 0.0706\n",
      "Epoch 322/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9844 - loss: 0.0507 - val_accuracy: 0.9823 - val_loss: 0.0573\n",
      "Epoch 323/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9848 - loss: 0.0498 - val_accuracy: 0.9838 - val_loss: 0.0565\n",
      "Epoch 324/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9880 - loss: 0.0474 - val_accuracy: 0.9831 - val_loss: 0.0600\n",
      "Epoch 325/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9858 - loss: 0.0458 - val_accuracy: 0.9838 - val_loss: 0.0580\n",
      "Epoch 326/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9864 - loss: 0.0542 - val_accuracy: 0.9831 - val_loss: 0.0566\n"
     ]
    }
   ],
   "source": [
    "# 학습이 언제 자동 중단될지를 설정합니다.\n",
    "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=20)\n",
    "\n",
    "# 최적화 모델이 저장될 폴더와 모델의 이름을 정합니다.\n",
    "modelpath=\"./data/model/bestmodel.keras\"\n",
    "\n",
    "# 최적화 모델을 업데이트하고 저장합니다.\n",
    "checkpointer = ModelCheckpoint(filepath=modelpath, monitor='val_loss', verbose=0, save_best_only=True)\n",
    "\n",
    "# 모델을 실행합니다.\n",
    "history=model.fit(X_train, y_train, epochs=2000, batch_size=500, validation_split=0.25, verbose=1,\n",
    "                        callbacks=[early_stopping_callback,checkpointer])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 394,
     "status": "ok",
     "timestamp": 1689665278512,
     "user": {
      "displayName": "junhwa lee",
      "userId": "11332889748979012167"
     },
     "user_tz": -540
    },
    "id": "pP0Wcpbb_nG6",
    "outputId": "33ecf917-c894-45bc-b82d-33bdbd1be8d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9778 - loss: 0.0833 \n",
      "Test accuracy: 0.9776923060417175\n"
     ]
    }
   ],
   "source": [
    "# 테스트 결과를 출력합니다.\n",
    "score=model.evaluate(X_test, y_test)\n",
    "print('Test accuracy:', score[1])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
