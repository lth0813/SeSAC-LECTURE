{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ftw5hyfw_nGs"
   },
   "source": [
    "# 모델의 성능 향상시키기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lD8i9xrq_nGw"
   },
   "source": [
    "### 1. 데이터의 확인과 검증셋"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "executionInfo": {
     "elapsed": 4797,
     "status": "ok",
     "timestamp": 1690333106925,
     "user": {
      "displayName": "junhwa lee",
      "userId": "11332889748979012167"
     },
     "user_tz": -540
    },
    "id": "9Usj9sc8_nGx",
    "outputId": "2289445b-bf2d-43b8-ab2e-50173f9c77fb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.99680</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.99700</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.99800</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6492</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.039</td>\n",
       "      <td>24.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>0.99114</td>\n",
       "      <td>3.27</td>\n",
       "      <td>0.50</td>\n",
       "      <td>11.2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6493</th>\n",
       "      <td>6.6</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.36</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.047</td>\n",
       "      <td>57.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>0.99490</td>\n",
       "      <td>3.15</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.6</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6494</th>\n",
       "      <td>6.5</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.19</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.041</td>\n",
       "      <td>30.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>0.99254</td>\n",
       "      <td>2.99</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6495</th>\n",
       "      <td>5.5</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.022</td>\n",
       "      <td>20.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.98869</td>\n",
       "      <td>3.34</td>\n",
       "      <td>0.38</td>\n",
       "      <td>12.8</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6496</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.020</td>\n",
       "      <td>22.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0.98941</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.32</td>\n",
       "      <td>11.8</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6497 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0     1     2    3      4     5      6        7     8     9     10  \\\n",
       "0      7.4  0.70  0.00  1.9  0.076  11.0   34.0  0.99780  3.51  0.56   9.4   \n",
       "1      7.8  0.88  0.00  2.6  0.098  25.0   67.0  0.99680  3.20  0.68   9.8   \n",
       "2      7.8  0.76  0.04  2.3  0.092  15.0   54.0  0.99700  3.26  0.65   9.8   \n",
       "3     11.2  0.28  0.56  1.9  0.075  17.0   60.0  0.99800  3.16  0.58   9.8   \n",
       "4      7.4  0.70  0.00  1.9  0.076  11.0   34.0  0.99780  3.51  0.56   9.4   \n",
       "...    ...   ...   ...  ...    ...   ...    ...      ...   ...   ...   ...   \n",
       "6492   6.2  0.21  0.29  1.6  0.039  24.0   92.0  0.99114  3.27  0.50  11.2   \n",
       "6493   6.6  0.32  0.36  8.0  0.047  57.0  168.0  0.99490  3.15  0.46   9.6   \n",
       "6494   6.5  0.24  0.19  1.2  0.041  30.0  111.0  0.99254  2.99  0.46   9.4   \n",
       "6495   5.5  0.29  0.30  1.1  0.022  20.0  110.0  0.98869  3.34  0.38  12.8   \n",
       "6496   6.0  0.21  0.38  0.8  0.020  22.0   98.0  0.98941  3.26  0.32  11.8   \n",
       "\n",
       "      11  12  \n",
       "0      5   1  \n",
       "1      5   1  \n",
       "2      5   1  \n",
       "3      6   1  \n",
       "4      5   1  \n",
       "...   ..  ..  \n",
       "6492   6   0  \n",
       "6493   5   0  \n",
       "6494   6   0  \n",
       "6495   7   0  \n",
       "6496   6   0  \n",
       "\n",
       "[6497 rows x 13 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "# 와인 데이터를 불러옵니다.\n",
    "df = pd.read_csv('./data/wine.csv', header=None)\n",
    "\n",
    "# 데이터를 미리 보겠습니다.\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 380,
     "status": "ok",
     "timestamp": 1690333109692,
     "user": {
      "displayName": "junhwa lee",
      "userId": "11332889748979012167"
     },
     "user_tz": -540
    },
    "id": "m0ZlAXHN_nGy"
   },
   "outputs": [],
   "source": [
    "# 와인의 속성을 X로 와인의 분류를 y로 저장합니다.\n",
    "X = df.iloc[:,0:12]\n",
    "y = df.iloc[:,12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6935,
     "status": "ok",
     "timestamp": 1690333118735,
     "user": {
      "displayName": "junhwa lee",
      "userId": "11332889748979012167"
     },
     "user_tz": -540
    },
    "id": "TpeC4rTC_nGz",
    "outputId": "4e59866f-ddbe-4077-bd67-d74be06a61fb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">390</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">372</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">104</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │               <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)                  │             \u001b[38;5;34m390\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m)                  │             \u001b[38;5;34m372\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)                   │             \u001b[38;5;34m104\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │               \u001b[38;5;34m9\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">875</span> (3.42 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m875\u001b[0m (3.42 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">875</span> (3.42 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m875\u001b[0m (3.42 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.7558 - loss: 1.9709 - val_accuracy: 0.7500 - val_loss: 1.7307\n",
      "Epoch 2/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7501 - loss: 1.5994 - val_accuracy: 0.7500 - val_loss: 1.2843\n",
      "Epoch 3/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7485 - loss: 1.1191 - val_accuracy: 0.7500 - val_loss: 0.9053\n",
      "Epoch 4/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7532 - loss: 0.7874 - val_accuracy: 0.7500 - val_loss: 0.5716\n",
      "Epoch 5/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7516 - loss: 0.4918 - val_accuracy: 0.7500 - val_loss: 0.4042\n",
      "Epoch 6/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7607 - loss: 0.4053 - val_accuracy: 0.7762 - val_loss: 0.3976\n",
      "Epoch 7/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7847 - loss: 0.3702 - val_accuracy: 0.7985 - val_loss: 0.3602\n",
      "Epoch 8/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8270 - loss: 0.3357 - val_accuracy: 0.8808 - val_loss: 0.3314\n",
      "Epoch 9/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8931 - loss: 0.3007 - val_accuracy: 0.8892 - val_loss: 0.3000\n",
      "Epoch 10/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9090 - loss: 0.2696 - val_accuracy: 0.9077 - val_loss: 0.2716\n",
      "Epoch 11/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9237 - loss: 0.2414 - val_accuracy: 0.9169 - val_loss: 0.2496\n",
      "Epoch 12/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9225 - loss: 0.2391 - val_accuracy: 0.9154 - val_loss: 0.2390\n",
      "Epoch 13/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9304 - loss: 0.2169 - val_accuracy: 0.9185 - val_loss: 0.2301\n",
      "Epoch 14/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9296 - loss: 0.2109 - val_accuracy: 0.9215 - val_loss: 0.2243\n",
      "Epoch 15/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9323 - loss: 0.2072 - val_accuracy: 0.9208 - val_loss: 0.2193\n",
      "Epoch 16/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9327 - loss: 0.2025 - val_accuracy: 0.9231 - val_loss: 0.2158\n",
      "Epoch 17/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9363 - loss: 0.1910 - val_accuracy: 0.9231 - val_loss: 0.2133\n",
      "Epoch 18/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9306 - loss: 0.2016 - val_accuracy: 0.9215 - val_loss: 0.2121\n",
      "Epoch 19/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9376 - loss: 0.1869 - val_accuracy: 0.9238 - val_loss: 0.2079\n",
      "Epoch 20/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9386 - loss: 0.1858 - val_accuracy: 0.9254 - val_loss: 0.2062\n",
      "Epoch 21/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9357 - loss: 0.1906 - val_accuracy: 0.9262 - val_loss: 0.2031\n",
      "Epoch 22/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9371 - loss: 0.1882 - val_accuracy: 0.9262 - val_loss: 0.2019\n",
      "Epoch 23/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9394 - loss: 0.1799 - val_accuracy: 0.9277 - val_loss: 0.1987\n",
      "Epoch 24/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9381 - loss: 0.1845 - val_accuracy: 0.9269 - val_loss: 0.1985\n",
      "Epoch 25/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9389 - loss: 0.1771 - val_accuracy: 0.9285 - val_loss: 0.1957\n",
      "Epoch 26/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9419 - loss: 0.1741 - val_accuracy: 0.9277 - val_loss: 0.1952\n",
      "Epoch 27/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9394 - loss: 0.1769 - val_accuracy: 0.9308 - val_loss: 0.1917\n",
      "Epoch 28/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9415 - loss: 0.1673 - val_accuracy: 0.9315 - val_loss: 0.1904\n",
      "Epoch 29/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9477 - loss: 0.1599 - val_accuracy: 0.9308 - val_loss: 0.1879\n",
      "Epoch 30/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9370 - loss: 0.1742 - val_accuracy: 0.9300 - val_loss: 0.1883\n",
      "Epoch 31/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9422 - loss: 0.1646 - val_accuracy: 0.9315 - val_loss: 0.1841\n",
      "Epoch 32/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9422 - loss: 0.1672 - val_accuracy: 0.9308 - val_loss: 0.1832\n",
      "Epoch 33/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9377 - loss: 0.1708 - val_accuracy: 0.9315 - val_loss: 0.1835\n",
      "Epoch 34/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9417 - loss: 0.1642 - val_accuracy: 0.9338 - val_loss: 0.1784\n",
      "Epoch 35/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9405 - loss: 0.1659 - val_accuracy: 0.9323 - val_loss: 0.1818\n",
      "Epoch 36/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9454 - loss: 0.1533 - val_accuracy: 0.9354 - val_loss: 0.1758\n",
      "Epoch 37/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9436 - loss: 0.1592 - val_accuracy: 0.9323 - val_loss: 0.1748\n",
      "Epoch 38/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9434 - loss: 0.1539 - val_accuracy: 0.9323 - val_loss: 0.1737\n",
      "Epoch 39/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9431 - loss: 0.1581 - val_accuracy: 0.9346 - val_loss: 0.1709\n",
      "Epoch 40/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9440 - loss: 0.1555 - val_accuracy: 0.9315 - val_loss: 0.1710\n",
      "Epoch 41/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9480 - loss: 0.1473 - val_accuracy: 0.9431 - val_loss: 0.1665\n",
      "Epoch 42/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9450 - loss: 0.1536 - val_accuracy: 0.9331 - val_loss: 0.1702\n",
      "Epoch 43/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9490 - loss: 0.1452 - val_accuracy: 0.9438 - val_loss: 0.1656\n",
      "Epoch 44/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9457 - loss: 0.1543 - val_accuracy: 0.9338 - val_loss: 0.1680\n",
      "Epoch 45/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9485 - loss: 0.1426 - val_accuracy: 0.9423 - val_loss: 0.1602\n",
      "Epoch 46/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9467 - loss: 0.1471 - val_accuracy: 0.9415 - val_loss: 0.1589\n",
      "Epoch 47/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9476 - loss: 0.1469 - val_accuracy: 0.9415 - val_loss: 0.1566\n",
      "Epoch 48/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9521 - loss: 0.1352 - val_accuracy: 0.9392 - val_loss: 0.1576\n",
      "Epoch 49/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9470 - loss: 0.1451 - val_accuracy: 0.9423 - val_loss: 0.1539\n",
      "Epoch 50/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9479 - loss: 0.1380 - val_accuracy: 0.9454 - val_loss: 0.1513\n"
     ]
    }
   ],
   "source": [
    "# 학습셋과 테스트셋으로 나눕니다.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True)\n",
    "\n",
    "# 모델 구조를 설정합니다.\n",
    "model = Sequential()\n",
    "model.add(Dense(30,  input_dim=12, activation='relu'))\n",
    "model.add(Dense(12, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.summary()\n",
    "\n",
    "# 모델을 컴파일합니다.\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# 모델을 실행합니다.\n",
    "history=model.fit(X_train, y_train, epochs=50, batch_size=500, validation_split=0.25) # 0.8 x 0.25 = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 385,
     "status": "ok",
     "timestamp": 1690333122290,
     "user": {
      "displayName": "junhwa lee",
      "userId": "11332889748979012167"
     },
     "user_tz": -540
    },
    "id": "Fqe8H_Cb_nGz",
    "outputId": "58b62b21-0a87-4de6-9b0e-149aa88b8eaa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9564 - loss: 0.1246 \n",
      "Test accuracy: 0.9515384435653687\n"
     ]
    }
   ],
   "source": [
    "# 테스트 결과를 출력합니다.\n",
    "score=model.evaluate(X_test, y_test)\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1nv462wz_nG0"
   },
   "source": [
    "## 2. 모델 업데이트하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jbJimFFF_nG1"
   },
   "source": [
    "### 기본 코드 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 383,
     "status": "ok",
     "timestamp": 1690333128648,
     "user": {
      "displayName": "junhwa lee",
      "userId": "11332889748979012167"
     },
     "user_tz": -540
    },
    "id": "AbHJ3gjb_nG1",
    "outputId": "7277ec77-9ece-4617-b274-ed370bb0f308"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">390</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">372</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">104</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │               <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)                  │             \u001b[38;5;34m390\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m)                  │             \u001b[38;5;34m372\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)                   │             \u001b[38;5;34m104\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │               \u001b[38;5;34m9\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">875</span> (3.42 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m875\u001b[0m (3.42 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">875</span> (3.42 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m875\u001b[0m (3.42 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# 와인 데이터를 불러옵니다.\n",
    "df = pd.read_csv('./data/wine.csv', header=None)\n",
    "\n",
    "# 와인의 속성을 X로 와인의 분류를 y로 저장합니다.\n",
    "X = df.iloc[:,0:12]\n",
    "y = df.iloc[:,12]\n",
    "\n",
    "# 학습셋과 테스트셋으로 나눕니다.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,\n",
    "                                                    shuffle=True)\n",
    "\n",
    "# 모델 구조를 설정합니다.\n",
    "model = Sequential()\n",
    "model.add(Dense(30,  input_dim=12, activation='relu'))\n",
    "model.add(Dense(12, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.summary()\n",
    "\n",
    "# 모델을 컴파일합니다.\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v8wHnkFW_nG2"
   },
   "source": [
    "### 모델의 저장 설정 및 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5658,
     "status": "ok",
     "timestamp": 1690333145538,
     "user": {
      "displayName": "junhwa lee",
      "userId": "11332889748979012167"
     },
     "user_tz": -540
    },
    "id": "cZ7qFKZe_nG2",
    "outputId": "a1ac2a31-928d-4d81-8b88-129805d8ea12"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: saving model to ./data/model/all/01-0.7692.keras\n",
      "\n",
      "Epoch 2: saving model to ./data/model/all/02-0.7300.keras\n",
      "\n",
      "Epoch 3: saving model to ./data/model/all/03-0.7685.keras\n",
      "\n",
      "Epoch 4: saving model to ./data/model/all/04-0.8246.keras\n",
      "\n",
      "Epoch 5: saving model to ./data/model/all/05-0.8585.keras\n",
      "\n",
      "Epoch 6: saving model to ./data/model/all/06-0.8462.keras\n",
      "\n",
      "Epoch 7: saving model to ./data/model/all/07-0.8762.keras\n",
      "\n",
      "Epoch 8: saving model to ./data/model/all/08-0.8923.keras\n",
      "\n",
      "Epoch 9: saving model to ./data/model/all/09-0.9054.keras\n",
      "\n",
      "Epoch 10: saving model to ./data/model/all/10-0.9138.keras\n",
      "\n",
      "Epoch 11: saving model to ./data/model/all/11-0.9200.keras\n",
      "\n",
      "Epoch 12: saving model to ./data/model/all/12-0.9269.keras\n",
      "\n",
      "Epoch 13: saving model to ./data/model/all/13-0.9308.keras\n",
      "\n",
      "Epoch 14: saving model to ./data/model/all/14-0.9338.keras\n",
      "\n",
      "Epoch 15: saving model to ./data/model/all/15-0.9354.keras\n",
      "\n",
      "Epoch 16: saving model to ./data/model/all/16-0.9369.keras\n",
      "\n",
      "Epoch 17: saving model to ./data/model/all/17-0.9369.keras\n",
      "\n",
      "Epoch 18: saving model to ./data/model/all/18-0.9377.keras\n",
      "\n",
      "Epoch 19: saving model to ./data/model/all/19-0.9369.keras\n",
      "\n",
      "Epoch 20: saving model to ./data/model/all/20-0.9392.keras\n",
      "\n",
      "Epoch 21: saving model to ./data/model/all/21-0.9385.keras\n",
      "\n",
      "Epoch 22: saving model to ./data/model/all/22-0.9392.keras\n",
      "\n",
      "Epoch 23: saving model to ./data/model/all/23-0.9392.keras\n",
      "\n",
      "Epoch 24: saving model to ./data/model/all/24-0.9392.keras\n",
      "\n",
      "Epoch 25: saving model to ./data/model/all/25-0.9400.keras\n",
      "\n",
      "Epoch 26: saving model to ./data/model/all/26-0.9408.keras\n",
      "\n",
      "Epoch 27: saving model to ./data/model/all/27-0.9408.keras\n",
      "\n",
      "Epoch 28: saving model to ./data/model/all/28-0.9415.keras\n",
      "\n",
      "Epoch 29: saving model to ./data/model/all/29-0.9408.keras\n",
      "\n",
      "Epoch 30: saving model to ./data/model/all/30-0.9431.keras\n",
      "\n",
      "Epoch 31: saving model to ./data/model/all/31-0.9423.keras\n",
      "\n",
      "Epoch 32: saving model to ./data/model/all/32-0.9423.keras\n",
      "\n",
      "Epoch 33: saving model to ./data/model/all/33-0.9431.keras\n",
      "\n",
      "Epoch 34: saving model to ./data/model/all/34-0.9454.keras\n",
      "\n",
      "Epoch 35: saving model to ./data/model/all/35-0.9454.keras\n",
      "\n",
      "Epoch 36: saving model to ./data/model/all/36-0.9454.keras\n",
      "\n",
      "Epoch 37: saving model to ./data/model/all/37-0.9462.keras\n",
      "\n",
      "Epoch 38: saving model to ./data/model/all/38-0.9469.keras\n",
      "\n",
      "Epoch 39: saving model to ./data/model/all/39-0.9477.keras\n",
      "\n",
      "Epoch 40: saving model to ./data/model/all/40-0.9477.keras\n",
      "\n",
      "Epoch 41: saving model to ./data/model/all/41-0.9485.keras\n",
      "\n",
      "Epoch 42: saving model to ./data/model/all/42-0.9492.keras\n",
      "\n",
      "Epoch 43: saving model to ./data/model/all/43-0.9492.keras\n",
      "\n",
      "Epoch 44: saving model to ./data/model/all/44-0.9508.keras\n",
      "\n",
      "Epoch 45: saving model to ./data/model/all/45-0.9508.keras\n",
      "\n",
      "Epoch 46: saving model to ./data/model/all/46-0.9500.keras\n",
      "\n",
      "Epoch 47: saving model to ./data/model/all/47-0.9515.keras\n",
      "\n",
      "Epoch 48: saving model to ./data/model/all/48-0.9515.keras\n",
      "\n",
      "Epoch 49: saving model to ./data/model/all/49-0.9515.keras\n",
      "\n",
      "Epoch 50: saving model to ./data/model/all/50-0.9508.keras\n"
     ]
    }
   ],
   "source": [
    "# 모델 저장의 조건을 설정합니다.\n",
    "modelpath=\"./data/model/all/{epoch:02d}-{val_accuracy:.4f}.keras\"\n",
    "checkpointer = ModelCheckpoint(filepath=modelpath, verbose=1)\n",
    "\n",
    "# 모델을 실행합니다.\n",
    "history=model.fit(X_train, y_train, epochs=50, batch_size=500, validation_split=0.25, verbose=0,\n",
    "                  callbacks=[checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 383,
     "status": "ok",
     "timestamp": 1690333149724,
     "user": {
      "displayName": "junhwa lee",
      "userId": "11332889748979012167"
     },
     "user_tz": -540
    },
    "id": "bcOwXzrp_nG3",
    "outputId": "b45fc2b1-47b0-4aec-8e23-bbc3ad0586ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9442 - loss: 0.1441\n",
      "Test accuracy: 0.9430769085884094\n"
     ]
    }
   ],
   "source": [
    "# 테스트 결과를 출력합니다.\n",
    "score=model.evaluate(X_test, y_test)\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HX_DdAlb_nG3"
   },
   "source": [
    "## 3. 그래프로 과적합 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 202407,
     "status": "ok",
     "timestamp": 1690333370929,
     "user": {
      "displayName": "junhwa lee",
      "userId": "11332889748979012167"
     },
     "user_tz": -540
    },
    "id": "pDwxitjb_nG3",
    "outputId": "8aaede37-cd33-401c-d4db-c25dca959540"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/2000\n",
      "10/10 ━━━━━━━━━━━━━━━━━━━━ accuracy: 0.9582 - loss: 0.1133 - val_accuracy: 0.9623 - val_loss: 0.1137\n",
      "Epoch 100/2000\n",
      "10/10 ━━━━━━━━━━━━━━━━━━━━ accuracy: 0.9749 - loss: 0.0833 - val_accuracy: 0.9769 - val_loss: 0.0899\n",
      "Epoch 150/2000\n",
      "10/10 ━━━━━━━━━━━━━━━━━━━━ accuracy: 0.9820 - loss: 0.0604 - val_accuracy: 0.9838 - val_loss: 0.0688\n",
      "Epoch 200/2000\n",
      "10/10 ━━━━━━━━━━━━━━━━━━━━ accuracy: 0.9851 - loss: 0.0532 - val_accuracy: 0.9862 - val_loss: 0.0623\n",
      "Epoch 250/2000\n",
      "10/10 ━━━━━━━━━━━━━━━━━━━━ accuracy: 0.9854 - loss: 0.0498 - val_accuracy: 0.9862 - val_loss: 0.0593\n",
      "Epoch 300/2000\n",
      "10/10 ━━━━━━━━━━━━━━━━━━━━ accuracy: 0.9872 - loss: 0.0472 - val_accuracy: 0.9862 - val_loss: 0.0630\n",
      "Epoch 350/2000\n",
      "10/10 ━━━━━━━━━━━━━━━━━━━━ accuracy: 0.9892 - loss: 0.0442 - val_accuracy: 0.9877 - val_loss: 0.0621\n",
      "Epoch 400/2000\n",
      "10/10 ━━━━━━━━━━━━━━━━━━━━ accuracy: 0.9877 - loss: 0.0423 - val_accuracy: 0.9838 - val_loss: 0.0641\n",
      "Epoch 450/2000\n",
      "10/10 ━━━━━━━━━━━━━━━━━━━━ accuracy: 0.9905 - loss: 0.0400 - val_accuracy: 0.9915 - val_loss: 0.0543\n",
      "Epoch 500/2000\n",
      "10/10 ━━━━━━━━━━━━━━━━━━━━ accuracy: 0.9910 - loss: 0.0370 - val_accuracy: 0.9908 - val_loss: 0.0536\n",
      "Epoch 550/2000\n",
      "10/10 ━━━━━━━━━━━━━━━━━━━━ accuracy: 0.9908 - loss: 0.0370 - val_accuracy: 0.9908 - val_loss: 0.0540\n",
      "Epoch 600/2000\n",
      "10/10 ━━━━━━━━━━━━━━━━━━━━ accuracy: 0.9908 - loss: 0.0367 - val_accuracy: 0.9908 - val_loss: 0.0519\n",
      "Epoch 650/2000\n",
      "10/10 ━━━━━━━━━━━━━━━━━━━━ accuracy: 0.9900 - loss: 0.0400 - val_accuracy: 0.9908 - val_loss: 0.0559\n",
      "Epoch 700/2000\n",
      "10/10 ━━━━━━━━━━━━━━━━━━━━ accuracy: 0.9926 - loss: 0.0326 - val_accuracy: 0.9869 - val_loss: 0.0560\n",
      "Epoch 750/2000\n",
      "10/10 ━━━━━━━━━━━━━━━━━━━━ accuracy: 0.9923 - loss: 0.0341 - val_accuracy: 0.9923 - val_loss: 0.0519\n",
      "Epoch 800/2000\n",
      "10/10 ━━━━━━━━━━━━━━━━━━━━ accuracy: 0.9923 - loss: 0.0315 - val_accuracy: 0.9908 - val_loss: 0.0538\n",
      "Epoch 850/2000\n",
      "10/10 ━━━━━━━━━━━━━━━━━━━━ accuracy: 0.9936 - loss: 0.0315 - val_accuracy: 0.9892 - val_loss: 0.0550\n",
      "Epoch 900/2000\n",
      "10/10 ━━━━━━━━━━━━━━━━━━━━ accuracy: 0.9905 - loss: 0.0347 - val_accuracy: 0.9885 - val_loss: 0.0565\n",
      "Epoch 950/2000\n",
      "10/10 ━━━━━━━━━━━━━━━━━━━━ accuracy: 0.9933 - loss: 0.0297 - val_accuracy: 0.9900 - val_loss: 0.0518\n",
      "Epoch 1000/2000\n",
      "10/10 ━━━━━━━━━━━━━━━━━━━━ accuracy: 0.9918 - loss: 0.0314 - val_accuracy: 0.9862 - val_loss: 0.0638\n",
      "Epoch 1050/2000\n",
      "10/10 ━━━━━━━━━━━━━━━━━━━━ accuracy: 0.9936 - loss: 0.0291 - val_accuracy: 0.9908 - val_loss: 0.0503\n",
      "Epoch 1100/2000\n",
      "10/10 ━━━━━━━━━━━━━━━━━━━━ accuracy: 0.9928 - loss: 0.0293 - val_accuracy: 0.9908 - val_loss: 0.0502\n",
      "Epoch 1150/2000\n",
      "10/10 ━━━━━━━━━━━━━━━━━━━━ accuracy: 0.9926 - loss: 0.0298 - val_accuracy: 0.9869 - val_loss: 0.0570\n",
      "Epoch 1200/2000\n",
      "10/10 ━━━━━━━━━━━━━━━━━━━━ accuracy: 0.9931 - loss: 0.0319 - val_accuracy: 0.9915 - val_loss: 0.0538\n",
      "Epoch 1250/2000\n",
      "10/10 ━━━━━━━━━━━━━━━━━━━━ accuracy: 0.9938 - loss: 0.0270 - val_accuracy: 0.9915 - val_loss: 0.0498\n",
      "Epoch 1300/2000\n",
      "10/10 ━━━━━━━━━━━━━━━━━━━━ accuracy: 0.9946 - loss: 0.0272 - val_accuracy: 0.9915 - val_loss: 0.0509\n",
      "Epoch 1350/2000\n",
      "10/10 ━━━━━━━━━━━━━━━━━━━━ accuracy: 0.9941 - loss: 0.0275 - val_accuracy: 0.9908 - val_loss: 0.0514\n",
      "Epoch 1400/2000\n",
      "10/10 ━━━━━━━━━━━━━━━━━━━━ accuracy: 0.9936 - loss: 0.0261 - val_accuracy: 0.9923 - val_loss: 0.0508\n",
      "Epoch 1450/2000\n",
      "10/10 ━━━━━━━━━━━━━━━━━━━━ accuracy: 0.9923 - loss: 0.0285 - val_accuracy: 0.9846 - val_loss: 0.0642\n",
      "Epoch 1500/2000\n",
      "10/10 ━━━━━━━━━━━━━━━━━━━━ accuracy: 0.9946 - loss: 0.0259 - val_accuracy: 0.9923 - val_loss: 0.0505\n",
      "Epoch 1550/2000\n",
      "10/10 ━━━━━━━━━━━━━━━━━━━━ accuracy: 0.9944 - loss: 0.0243 - val_accuracy: 0.9908 - val_loss: 0.0502\n",
      "Epoch 1600/2000\n",
      "10/10 ━━━━━━━━━━━━━━━━━━━━ accuracy: 0.9954 - loss: 0.0240 - val_accuracy: 0.9915 - val_loss: 0.0510\n",
      "Epoch 1650/2000\n",
      "10/10 ━━━━━━━━━━━━━━━━━━━━ accuracy: 0.9944 - loss: 0.0222 - val_accuracy: 0.9915 - val_loss: 0.0518\n",
      "Epoch 1700/2000\n",
      "10/10 ━━━━━━━━━━━━━━━━━━━━ accuracy: 0.9938 - loss: 0.0229 - val_accuracy: 0.9877 - val_loss: 0.0569\n",
      "Epoch 1750/2000\n",
      "10/10 ━━━━━━━━━━━━━━━━━━━━ accuracy: 0.9949 - loss: 0.0219 - val_accuracy: 0.9885 - val_loss: 0.0565\n",
      "Epoch 1800/2000\n",
      "10/10 ━━━━━━━━━━━━━━━━━━━━ accuracy: 0.9931 - loss: 0.0245 - val_accuracy: 0.9915 - val_loss: 0.0544\n",
      "Epoch 1850/2000\n",
      "10/10 ━━━━━━━━━━━━━━━━━━━━ accuracy: 0.9954 - loss: 0.0231 - val_accuracy: 0.9915 - val_loss: 0.0526\n",
      "Epoch 1900/2000\n",
      "10/10 ━━━━━━━━━━━━━━━━━━━━ accuracy: 0.9951 - loss: 0.0223 - val_accuracy: 0.9915 - val_loss: 0.0531\n",
      "Epoch 1950/2000\n",
      "10/10 ━━━━━━━━━━━━━━━━━━━━ accuracy: 0.9936 - loss: 0.0241 - val_accuracy: 0.9885 - val_loss: 0.0562\n",
      "Epoch 2000/2000\n",
      "10/10 ━━━━━━━━━━━━━━━━━━━━ accuracy: 0.9962 - loss: 0.0207 - val_accuracy: 0.9846 - val_loss: 0.0666\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import LambdaCallback\n",
    "import tensorflow as tf\n",
    "\n",
    "# 50번마다 한 번씩 출력하는 콜백 함수\n",
    "def custom_log(epoch, logs):\n",
    "    if (epoch + 1) % 50 == 0:\n",
    "        num_batches = len(X_train) // 500\n",
    "        print(f\"Epoch {epoch+1}/2000\") \n",
    "        tf.print(f\"{num_batches}/{num_batches} ━━━━━━━━━━━━━━━━━━━━ \"\n",
    "                 f\"accuracy: {logs['accuracy']:.4f} - loss: {logs['loss']:.4f} - \"\n",
    "                 f\"val_accuracy: {logs['val_accuracy']:.4f} - val_loss: {logs['val_loss']:.4f}\")\n",
    "show_status = LambdaCallback(on_epoch_end=custom_log)\n",
    "\n",
    "# 그래프 확인을 위한 긴 학습\n",
    "history=model.fit(X_train, y_train, epochs=2000, batch_size=500, validation_split=0.25, verbose=0, callbacks=show_status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "executionInfo": {
     "elapsed": 302,
     "status": "ok",
     "timestamp": 1689665185429,
     "user": {
      "displayName": "junhwa lee",
      "userId": "11332889748979012167"
     },
     "user_tz": -540
    },
    "id": "zjfuqmQi_nG3",
    "outputId": "5e063b00-d7d7-4583-ab63-5d19abbd41a8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.943546</td>\n",
       "      <td>0.150582</td>\n",
       "      <td>0.951538</td>\n",
       "      <td>0.145386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.942520</td>\n",
       "      <td>0.150171</td>\n",
       "      <td>0.951538</td>\n",
       "      <td>0.145063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.943546</td>\n",
       "      <td>0.149691</td>\n",
       "      <td>0.951538</td>\n",
       "      <td>0.144617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.944060</td>\n",
       "      <td>0.147804</td>\n",
       "      <td>0.953077</td>\n",
       "      <td>0.143880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.945086</td>\n",
       "      <td>0.146677</td>\n",
       "      <td>0.952308</td>\n",
       "      <td>0.142740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>0.994098</td>\n",
       "      <td>0.023762</td>\n",
       "      <td>0.990000</td>\n",
       "      <td>0.056442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>0.993585</td>\n",
       "      <td>0.026300</td>\n",
       "      <td>0.992308</td>\n",
       "      <td>0.053771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>0.995124</td>\n",
       "      <td>0.021154</td>\n",
       "      <td>0.991538</td>\n",
       "      <td>0.054268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>0.995638</td>\n",
       "      <td>0.020580</td>\n",
       "      <td>0.990769</td>\n",
       "      <td>0.054781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>0.996151</td>\n",
       "      <td>0.020651</td>\n",
       "      <td>0.984615</td>\n",
       "      <td>0.066585</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      accuracy      loss  val_accuracy  val_loss\n",
       "0     0.943546  0.150582      0.951538  0.145386\n",
       "1     0.942520  0.150171      0.951538  0.145063\n",
       "2     0.943546  0.149691      0.951538  0.144617\n",
       "3     0.944060  0.147804      0.953077  0.143880\n",
       "4     0.945086  0.146677      0.952308  0.142740\n",
       "...        ...       ...           ...       ...\n",
       "1995  0.994098  0.023762      0.990000  0.056442\n",
       "1996  0.993585  0.026300      0.992308  0.053771\n",
       "1997  0.995124  0.021154      0.991538  0.054268\n",
       "1998  0.995638  0.020580      0.990769  0.054781\n",
       "1999  0.996151  0.020651      0.984615  0.066585\n",
       "\n",
       "[2000 rows x 4 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# history에 저장된 학습 결과를 확인해 보겠습니다.\n",
    "hist_df=pd.DataFrame(history.history)\n",
    "hist_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 449
    },
    "executionInfo": {
     "elapsed": 871,
     "status": "ok",
     "timestamp": 1689665189006,
     "user": {
      "displayName": "junhwa lee",
      "userId": "11332889748979012167"
     },
     "user_tz": -540
    },
    "id": "yij0pMOC_nG4",
    "outputId": "f18455a4-99ea-4848-b5dd-517f3d672b6c"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# y_vloss에 테스트셋(여기서는 검증셋)의 오차를 저장합니다.\n",
    "y_vloss=hist_df['val_loss']\n",
    "\n",
    "# y_loss에 학습셋의 오차를 저장합니다.\n",
    "y_loss=hist_df['loss']\n",
    "\n",
    "#x 값을 지정하고 테스트셋(검증셋)의 오차를 빨간색으로, 학습셋의 오차를 파란색으로 표시합니다.\n",
    "x_len = np.arange(len(y_loss))\n",
    "plt.plot(x_len, y_vloss, \"o\", c=\"red\", markersize=2, label='Testset_loss')\n",
    "plt.plot(x_len, y_loss, \"o\", c=\"blue\", markersize=2, label='Trainset_loss')\n",
    "\n",
    "plt.legend(loc='upper right')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qfgIYVvS_nG4"
   },
   "source": [
    "## 4. 학습의 자동 중단"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "35U6o4cH_nG4"
   },
   "source": [
    "### 기본 코드 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 400,
     "status": "ok",
     "timestamp": 1689665204094,
     "user": {
      "displayName": "junhwa lee",
      "userId": "11332889748979012167"
     },
     "user_tz": -540
    },
    "id": "NOyIPFzB_nG5",
    "outputId": "6d4bd773-5eda-4286-fa14-c4290a192873"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">390</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">372</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">104</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │               <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)                  │             \u001b[38;5;34m390\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m)                  │             \u001b[38;5;34m372\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)                   │             \u001b[38;5;34m104\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │               \u001b[38;5;34m9\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">875</span> (3.42 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m875\u001b[0m (3.42 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">875</span> (3.42 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m875\u001b[0m (3.42 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# 와인 데이터를 불러옵니다.\n",
    "df = pd.read_csv('./data/wine.csv', header=None)\n",
    "\n",
    "# 와인의 속성을 X로 와인의 분류를 y로 저장합니다.\n",
    "X = df.iloc[:,0:12]\n",
    "y = df.iloc[:,12]\n",
    "\n",
    "# 학습셋과 테스트셋으로 나눕니다.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True)\n",
    "\n",
    "# 모델 구조를 설정합니다.\n",
    "model = Sequential()\n",
    "model.add(Dense(30,  input_dim=12, activation='relu'))\n",
    "model.add(Dense(12, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.summary()\n",
    "\n",
    "# 모델을 컴파일합니다.\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TVZTtnL4_nG5"
   },
   "source": [
    "### 학습의 자동 중단 및 최적화 모델 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10063,
     "status": "ok",
     "timestamp": 1689665363040,
     "user": {
      "displayName": "junhwa lee",
      "userId": "11332889748979012167"
     },
     "user_tz": -540
    },
    "id": "7EDUE8N5_nG5",
    "outputId": "d498420b-78e5-42b7-a8d2-e63b669b07a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.8228 - loss: 0.4367 - val_accuracy: 0.8969 - val_loss: 0.3219\n",
      "Epoch 2/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9017 - loss: 0.3084 - val_accuracy: 0.9046 - val_loss: 0.2796\n",
      "Epoch 3/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9008 - loss: 0.2824 - val_accuracy: 0.9023 - val_loss: 0.2661\n",
      "Epoch 4/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9081 - loss: 0.2622 - val_accuracy: 0.9192 - val_loss: 0.2474\n",
      "Epoch 5/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9252 - loss: 0.2372 - val_accuracy: 0.9208 - val_loss: 0.2348\n",
      "Epoch 6/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9344 - loss: 0.2177 - val_accuracy: 0.9223 - val_loss: 0.2238\n",
      "Epoch 7/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9317 - loss: 0.2200 - val_accuracy: 0.9246 - val_loss: 0.2160\n",
      "Epoch 8/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9350 - loss: 0.1999 - val_accuracy: 0.9246 - val_loss: 0.2099\n",
      "Epoch 9/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9358 - loss: 0.1981 - val_accuracy: 0.9254 - val_loss: 0.2012\n",
      "Epoch 10/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9362 - loss: 0.1914 - val_accuracy: 0.9254 - val_loss: 0.1946\n",
      "Epoch 11/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9446 - loss: 0.1738 - val_accuracy: 0.9262 - val_loss: 0.1910\n",
      "Epoch 12/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9451 - loss: 0.1725 - val_accuracy: 0.9254 - val_loss: 0.1886\n",
      "Epoch 13/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9430 - loss: 0.1683 - val_accuracy: 0.9269 - val_loss: 0.1860\n",
      "Epoch 14/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9396 - loss: 0.1782 - val_accuracy: 0.9238 - val_loss: 0.1856\n",
      "Epoch 15/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9391 - loss: 0.1738 - val_accuracy: 0.9269 - val_loss: 0.1829\n",
      "Epoch 16/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9438 - loss: 0.1635 - val_accuracy: 0.9262 - val_loss: 0.1808\n",
      "Epoch 17/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9412 - loss: 0.1689 - val_accuracy: 0.9269 - val_loss: 0.1779\n",
      "Epoch 18/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9407 - loss: 0.1671 - val_accuracy: 0.9285 - val_loss: 0.1763\n",
      "Epoch 19/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9418 - loss: 0.1682 - val_accuracy: 0.9285 - val_loss: 0.1753\n",
      "Epoch 20/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9408 - loss: 0.1657 - val_accuracy: 0.9292 - val_loss: 0.1724\n",
      "Epoch 21/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9444 - loss: 0.1605 - val_accuracy: 0.9308 - val_loss: 0.1699\n",
      "Epoch 22/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9455 - loss: 0.1540 - val_accuracy: 0.9300 - val_loss: 0.1679\n",
      "Epoch 23/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9469 - loss: 0.1540 - val_accuracy: 0.9300 - val_loss: 0.1658\n",
      "Epoch 24/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9476 - loss: 0.1503 - val_accuracy: 0.9315 - val_loss: 0.1639\n",
      "Epoch 25/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9469 - loss: 0.1478 - val_accuracy: 0.9323 - val_loss: 0.1615\n",
      "Epoch 26/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9452 - loss: 0.1576 - val_accuracy: 0.9308 - val_loss: 0.1607\n",
      "Epoch 27/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9496 - loss: 0.1389 - val_accuracy: 0.9377 - val_loss: 0.1577\n",
      "Epoch 28/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9493 - loss: 0.1415 - val_accuracy: 0.9377 - val_loss: 0.1543\n",
      "Epoch 29/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9504 - loss: 0.1433 - val_accuracy: 0.9338 - val_loss: 0.1549\n",
      "Epoch 30/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9533 - loss: 0.1453 - val_accuracy: 0.9385 - val_loss: 0.1524\n",
      "Epoch 31/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9498 - loss: 0.1434 - val_accuracy: 0.9415 - val_loss: 0.1458\n",
      "Epoch 32/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9505 - loss: 0.1417 - val_accuracy: 0.9438 - val_loss: 0.1427\n",
      "Epoch 33/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9578 - loss: 0.1283 - val_accuracy: 0.9469 - val_loss: 0.1399\n",
      "Epoch 34/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9540 - loss: 0.1410 - val_accuracy: 0.9446 - val_loss: 0.1369\n",
      "Epoch 35/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9556 - loss: 0.1261 - val_accuracy: 0.9462 - val_loss: 0.1347\n",
      "Epoch 36/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9554 - loss: 0.1319 - val_accuracy: 0.9485 - val_loss: 0.1343\n",
      "Epoch 37/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9556 - loss: 0.1302 - val_accuracy: 0.9508 - val_loss: 0.1300\n",
      "Epoch 38/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9561 - loss: 0.1289 - val_accuracy: 0.9431 - val_loss: 0.1344\n",
      "Epoch 39/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9527 - loss: 0.1322 - val_accuracy: 0.9438 - val_loss: 0.1308\n",
      "Epoch 40/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9533 - loss: 0.1289 - val_accuracy: 0.9477 - val_loss: 0.1248\n",
      "Epoch 41/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9583 - loss: 0.1221 - val_accuracy: 0.9508 - val_loss: 0.1234\n",
      "Epoch 42/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9587 - loss: 0.1196 - val_accuracy: 0.9623 - val_loss: 0.1324\n",
      "Epoch 43/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9591 - loss: 0.1268 - val_accuracy: 0.9531 - val_loss: 0.1191\n",
      "Epoch 44/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9600 - loss: 0.1260 - val_accuracy: 0.9454 - val_loss: 0.1251\n",
      "Epoch 45/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9592 - loss: 0.1169 - val_accuracy: 0.9508 - val_loss: 0.1159\n",
      "Epoch 46/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9564 - loss: 0.1220 - val_accuracy: 0.9569 - val_loss: 0.1151\n",
      "Epoch 47/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9565 - loss: 0.1234 - val_accuracy: 0.9546 - val_loss: 0.1128\n",
      "Epoch 48/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9640 - loss: 0.1037 - val_accuracy: 0.9508 - val_loss: 0.1141\n",
      "Epoch 49/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9641 - loss: 0.1005 - val_accuracy: 0.9631 - val_loss: 0.1097\n",
      "Epoch 50/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9629 - loss: 0.1161 - val_accuracy: 0.9477 - val_loss: 0.1139\n",
      "Epoch 51/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9599 - loss: 0.1104 - val_accuracy: 0.9546 - val_loss: 0.1074\n",
      "Epoch 52/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9663 - loss: 0.0983 - val_accuracy: 0.9646 - val_loss: 0.1032\n",
      "Epoch 53/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9656 - loss: 0.1087 - val_accuracy: 0.9685 - val_loss: 0.1047\n",
      "Epoch 54/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9647 - loss: 0.1050 - val_accuracy: 0.9692 - val_loss: 0.1075\n",
      "Epoch 55/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9644 - loss: 0.1073 - val_accuracy: 0.9685 - val_loss: 0.1027\n",
      "Epoch 56/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9711 - loss: 0.1027 - val_accuracy: 0.9731 - val_loss: 0.0957\n",
      "Epoch 57/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9696 - loss: 0.1005 - val_accuracy: 0.9708 - val_loss: 0.0950\n",
      "Epoch 58/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9717 - loss: 0.0966 - val_accuracy: 0.9723 - val_loss: 0.0984\n",
      "Epoch 59/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9711 - loss: 0.1038 - val_accuracy: 0.9715 - val_loss: 0.0908\n",
      "Epoch 60/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9696 - loss: 0.0973 - val_accuracy: 0.9623 - val_loss: 0.0934\n",
      "Epoch 61/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9676 - loss: 0.0908 - val_accuracy: 0.9662 - val_loss: 0.0909\n",
      "Epoch 62/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9681 - loss: 0.0984 - val_accuracy: 0.9692 - val_loss: 0.0882\n",
      "Epoch 63/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9713 - loss: 0.0976 - val_accuracy: 0.9685 - val_loss: 0.0883\n",
      "Epoch 64/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9706 - loss: 0.0857 - val_accuracy: 0.9731 - val_loss: 0.0840\n",
      "Epoch 65/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9725 - loss: 0.0896 - val_accuracy: 0.9754 - val_loss: 0.0841\n",
      "Epoch 66/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9784 - loss: 0.0755 - val_accuracy: 0.9738 - val_loss: 0.0822\n",
      "Epoch 67/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9731 - loss: 0.0878 - val_accuracy: 0.9746 - val_loss: 0.0805\n",
      "Epoch 68/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9728 - loss: 0.0861 - val_accuracy: 0.9762 - val_loss: 0.0801\n",
      "Epoch 69/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9731 - loss: 0.0840 - val_accuracy: 0.9769 - val_loss: 0.0789\n",
      "Epoch 70/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9720 - loss: 0.0876 - val_accuracy: 0.9762 - val_loss: 0.0775\n",
      "Epoch 71/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9738 - loss: 0.0771 - val_accuracy: 0.9762 - val_loss: 0.0772\n",
      "Epoch 72/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9745 - loss: 0.0781 - val_accuracy: 0.9777 - val_loss: 0.0759\n",
      "Epoch 73/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9762 - loss: 0.0820 - val_accuracy: 0.9777 - val_loss: 0.0746\n",
      "Epoch 74/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9758 - loss: 0.0753 - val_accuracy: 0.9785 - val_loss: 0.0740\n",
      "Epoch 75/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9780 - loss: 0.0775 - val_accuracy: 0.9785 - val_loss: 0.0732\n",
      "Epoch 76/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9761 - loss: 0.0860 - val_accuracy: 0.9800 - val_loss: 0.0718\n",
      "Epoch 77/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9720 - loss: 0.0885 - val_accuracy: 0.9769 - val_loss: 0.0726\n",
      "Epoch 78/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9759 - loss: 0.0842 - val_accuracy: 0.9746 - val_loss: 0.0739\n",
      "Epoch 79/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9791 - loss: 0.0711 - val_accuracy: 0.9777 - val_loss: 0.0710\n",
      "Epoch 80/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9764 - loss: 0.0820 - val_accuracy: 0.9769 - val_loss: 0.0714\n",
      "Epoch 81/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9792 - loss: 0.0757 - val_accuracy: 0.9792 - val_loss: 0.0695\n",
      "Epoch 82/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9764 - loss: 0.0816 - val_accuracy: 0.9785 - val_loss: 0.0691\n",
      "Epoch 83/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9752 - loss: 0.0880 - val_accuracy: 0.9738 - val_loss: 0.0736\n",
      "Epoch 84/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9727 - loss: 0.0886 - val_accuracy: 0.9723 - val_loss: 0.0755\n",
      "Epoch 85/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9777 - loss: 0.0705 - val_accuracy: 0.9823 - val_loss: 0.0656\n",
      "Epoch 86/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9791 - loss: 0.0667 - val_accuracy: 0.9800 - val_loss: 0.0641\n",
      "Epoch 87/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9780 - loss: 0.0739 - val_accuracy: 0.9823 - val_loss: 0.0638\n",
      "Epoch 88/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9772 - loss: 0.0747 - val_accuracy: 0.9823 - val_loss: 0.0622\n",
      "Epoch 89/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9763 - loss: 0.0861 - val_accuracy: 0.9808 - val_loss: 0.0637\n",
      "Epoch 90/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9823 - loss: 0.0643 - val_accuracy: 0.9808 - val_loss: 0.0630\n",
      "Epoch 91/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9803 - loss: 0.0685 - val_accuracy: 0.9738 - val_loss: 0.0720\n",
      "Epoch 92/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9805 - loss: 0.0687 - val_accuracy: 0.9823 - val_loss: 0.0603\n",
      "Epoch 93/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9826 - loss: 0.0657 - val_accuracy: 0.9792 - val_loss: 0.0649\n",
      "Epoch 94/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9799 - loss: 0.0688 - val_accuracy: 0.9831 - val_loss: 0.0585\n",
      "Epoch 95/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9814 - loss: 0.0664 - val_accuracy: 0.9823 - val_loss: 0.0579\n",
      "Epoch 96/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9822 - loss: 0.0651 - val_accuracy: 0.9831 - val_loss: 0.0577\n",
      "Epoch 97/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9789 - loss: 0.0670 - val_accuracy: 0.9838 - val_loss: 0.0560\n",
      "Epoch 98/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9817 - loss: 0.0635 - val_accuracy: 0.9831 - val_loss: 0.0557\n",
      "Epoch 99/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9752 - loss: 0.0780 - val_accuracy: 0.9831 - val_loss: 0.0549\n",
      "Epoch 100/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9827 - loss: 0.0590 - val_accuracy: 0.9792 - val_loss: 0.0628\n",
      "Epoch 101/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9790 - loss: 0.0707 - val_accuracy: 0.9792 - val_loss: 0.0624\n",
      "Epoch 102/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9776 - loss: 0.0710 - val_accuracy: 0.9831 - val_loss: 0.0558\n",
      "Epoch 103/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9811 - loss: 0.0653 - val_accuracy: 0.9846 - val_loss: 0.0529\n",
      "Epoch 104/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9856 - loss: 0.0521 - val_accuracy: 0.9831 - val_loss: 0.0513\n",
      "Epoch 105/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9842 - loss: 0.0596 - val_accuracy: 0.9823 - val_loss: 0.0527\n",
      "Epoch 106/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9800 - loss: 0.0679 - val_accuracy: 0.9846 - val_loss: 0.0526\n",
      "Epoch 107/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9826 - loss: 0.0567 - val_accuracy: 0.9838 - val_loss: 0.0500\n",
      "Epoch 108/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9834 - loss: 0.0552 - val_accuracy: 0.9831 - val_loss: 0.0527\n",
      "Epoch 109/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9796 - loss: 0.0685 - val_accuracy: 0.9838 - val_loss: 0.0512\n",
      "Epoch 110/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9821 - loss: 0.0629 - val_accuracy: 0.9846 - val_loss: 0.0505\n",
      "Epoch 111/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9845 - loss: 0.0526 - val_accuracy: 0.9838 - val_loss: 0.0503\n",
      "Epoch 112/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9865 - loss: 0.0506 - val_accuracy: 0.9846 - val_loss: 0.0512\n",
      "Epoch 113/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9833 - loss: 0.0543 - val_accuracy: 0.9838 - val_loss: 0.0528\n",
      "Epoch 114/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9835 - loss: 0.0570 - val_accuracy: 0.9854 - val_loss: 0.0546\n",
      "Epoch 115/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9818 - loss: 0.0646 - val_accuracy: 0.9846 - val_loss: 0.0501\n",
      "Epoch 116/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9832 - loss: 0.0521 - val_accuracy: 0.9831 - val_loss: 0.0548\n",
      "Epoch 117/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9800 - loss: 0.0625 - val_accuracy: 0.9854 - val_loss: 0.0509\n",
      "Epoch 118/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9841 - loss: 0.0537 - val_accuracy: 0.9862 - val_loss: 0.0493\n",
      "Epoch 119/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9837 - loss: 0.0565 - val_accuracy: 0.9854 - val_loss: 0.0492\n",
      "Epoch 120/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9827 - loss: 0.0604 - val_accuracy: 0.9862 - val_loss: 0.0490\n",
      "Epoch 121/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9819 - loss: 0.0609 - val_accuracy: 0.9854 - val_loss: 0.0501\n",
      "Epoch 122/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9855 - loss: 0.0507 - val_accuracy: 0.9846 - val_loss: 0.0488\n",
      "Epoch 123/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9824 - loss: 0.0563 - val_accuracy: 0.9862 - val_loss: 0.0484\n",
      "Epoch 124/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9832 - loss: 0.0603 - val_accuracy: 0.9846 - val_loss: 0.0497\n",
      "Epoch 125/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9831 - loss: 0.0537 - val_accuracy: 0.9854 - val_loss: 0.0494\n",
      "Epoch 126/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9840 - loss: 0.0528 - val_accuracy: 0.9854 - val_loss: 0.0489\n",
      "Epoch 127/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9814 - loss: 0.0588 - val_accuracy: 0.9846 - val_loss: 0.0497\n",
      "Epoch 128/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9844 - loss: 0.0556 - val_accuracy: 0.9846 - val_loss: 0.0486\n",
      "Epoch 129/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9836 - loss: 0.0565 - val_accuracy: 0.9831 - val_loss: 0.0533\n",
      "Epoch 130/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9853 - loss: 0.0559 - val_accuracy: 0.9838 - val_loss: 0.0507\n",
      "Epoch 131/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9857 - loss: 0.0591 - val_accuracy: 0.9838 - val_loss: 0.0528\n",
      "Epoch 132/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9855 - loss: 0.0563 - val_accuracy: 0.9831 - val_loss: 0.0514\n",
      "Epoch 133/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9841 - loss: 0.0602 - val_accuracy: 0.9838 - val_loss: 0.0495\n",
      "Epoch 134/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9867 - loss: 0.0546 - val_accuracy: 0.9838 - val_loss: 0.0560\n",
      "Epoch 135/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9807 - loss: 0.0619 - val_accuracy: 0.9869 - val_loss: 0.0469\n",
      "Epoch 136/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9841 - loss: 0.0563 - val_accuracy: 0.9854 - val_loss: 0.0552\n",
      "Epoch 137/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9841 - loss: 0.0530 - val_accuracy: 0.9846 - val_loss: 0.0560\n",
      "Epoch 138/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9813 - loss: 0.0639 - val_accuracy: 0.9854 - val_loss: 0.0467\n",
      "Epoch 139/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9890 - loss: 0.0423 - val_accuracy: 0.9869 - val_loss: 0.0499\n",
      "Epoch 140/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9825 - loss: 0.0527 - val_accuracy: 0.9862 - val_loss: 0.0476\n",
      "Epoch 141/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9873 - loss: 0.0496 - val_accuracy: 0.9846 - val_loss: 0.0497\n",
      "Epoch 142/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9841 - loss: 0.0535 - val_accuracy: 0.9846 - val_loss: 0.0505\n",
      "Epoch 143/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9827 - loss: 0.0575 - val_accuracy: 0.9862 - val_loss: 0.0463\n",
      "Epoch 144/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9853 - loss: 0.0504 - val_accuracy: 0.9831 - val_loss: 0.0515\n",
      "Epoch 145/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9838 - loss: 0.0509 - val_accuracy: 0.9846 - val_loss: 0.0506\n",
      "Epoch 146/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9849 - loss: 0.0533 - val_accuracy: 0.9800 - val_loss: 0.0579\n",
      "Epoch 147/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9836 - loss: 0.0552 - val_accuracy: 0.9815 - val_loss: 0.0545\n",
      "Epoch 148/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9775 - loss: 0.0647 - val_accuracy: 0.9815 - val_loss: 0.0557\n",
      "Epoch 149/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9794 - loss: 0.0628 - val_accuracy: 0.9838 - val_loss: 0.0501\n",
      "Epoch 150/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9846 - loss: 0.0538 - val_accuracy: 0.9846 - val_loss: 0.0508\n",
      "Epoch 151/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9864 - loss: 0.0524 - val_accuracy: 0.9846 - val_loss: 0.0487\n",
      "Epoch 152/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9834 - loss: 0.0586 - val_accuracy: 0.9862 - val_loss: 0.0466\n",
      "Epoch 153/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9857 - loss: 0.0482 - val_accuracy: 0.9862 - val_loss: 0.0458\n",
      "Epoch 154/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9869 - loss: 0.0467 - val_accuracy: 0.9862 - val_loss: 0.0462\n",
      "Epoch 155/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9865 - loss: 0.0489 - val_accuracy: 0.9838 - val_loss: 0.0497\n",
      "Epoch 156/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9841 - loss: 0.0547 - val_accuracy: 0.9862 - val_loss: 0.0463\n",
      "Epoch 157/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9841 - loss: 0.0556 - val_accuracy: 0.9846 - val_loss: 0.0471\n",
      "Epoch 158/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9861 - loss: 0.0518 - val_accuracy: 0.9823 - val_loss: 0.0510\n",
      "Epoch 159/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9855 - loss: 0.0491 - val_accuracy: 0.9869 - val_loss: 0.0461\n",
      "Epoch 160/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9868 - loss: 0.0521 - val_accuracy: 0.9854 - val_loss: 0.0478\n",
      "Epoch 161/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9794 - loss: 0.0659 - val_accuracy: 0.9846 - val_loss: 0.0453\n",
      "Epoch 162/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9835 - loss: 0.0559 - val_accuracy: 0.9846 - val_loss: 0.0493\n",
      "Epoch 163/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9840 - loss: 0.0563 - val_accuracy: 0.9762 - val_loss: 0.0621\n",
      "Epoch 164/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9857 - loss: 0.0538 - val_accuracy: 0.9808 - val_loss: 0.0567\n",
      "Epoch 165/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9843 - loss: 0.0520 - val_accuracy: 0.9831 - val_loss: 0.0504\n",
      "Epoch 166/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9876 - loss: 0.0472 - val_accuracy: 0.9846 - val_loss: 0.0471\n",
      "Epoch 167/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9858 - loss: 0.0550 - val_accuracy: 0.9846 - val_loss: 0.0476\n",
      "Epoch 168/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9835 - loss: 0.0551 - val_accuracy: 0.9854 - val_loss: 0.0457\n",
      "Epoch 169/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9853 - loss: 0.0537 - val_accuracy: 0.9862 - val_loss: 0.0446\n",
      "Epoch 170/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9861 - loss: 0.0542 - val_accuracy: 0.9869 - val_loss: 0.0444\n",
      "Epoch 171/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9884 - loss: 0.0420 - val_accuracy: 0.9823 - val_loss: 0.0531\n",
      "Epoch 172/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9878 - loss: 0.0441 - val_accuracy: 0.9815 - val_loss: 0.0556\n",
      "Epoch 173/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9862 - loss: 0.0530 - val_accuracy: 0.9846 - val_loss: 0.0473\n",
      "Epoch 174/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9861 - loss: 0.0512 - val_accuracy: 0.9862 - val_loss: 0.0455\n",
      "Epoch 175/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9859 - loss: 0.0445 - val_accuracy: 0.9862 - val_loss: 0.0447\n",
      "Epoch 176/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9869 - loss: 0.0452 - val_accuracy: 0.9862 - val_loss: 0.0443\n",
      "Epoch 177/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9883 - loss: 0.0474 - val_accuracy: 0.9846 - val_loss: 0.0452\n",
      "Epoch 178/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9878 - loss: 0.0435 - val_accuracy: 0.9846 - val_loss: 0.0465\n",
      "Epoch 179/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9887 - loss: 0.0430 - val_accuracy: 0.9846 - val_loss: 0.0447\n",
      "Epoch 180/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9835 - loss: 0.0571 - val_accuracy: 0.9862 - val_loss: 0.0454\n",
      "Epoch 181/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9870 - loss: 0.0515 - val_accuracy: 0.9854 - val_loss: 0.0468\n",
      "Epoch 182/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9849 - loss: 0.0518 - val_accuracy: 0.9862 - val_loss: 0.0452\n",
      "Epoch 183/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9857 - loss: 0.0478 - val_accuracy: 0.9846 - val_loss: 0.0447\n",
      "Epoch 184/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9851 - loss: 0.0453 - val_accuracy: 0.9854 - val_loss: 0.0448\n",
      "Epoch 185/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9858 - loss: 0.0451 - val_accuracy: 0.9854 - val_loss: 0.0446\n",
      "Epoch 186/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9867 - loss: 0.0495 - val_accuracy: 0.9846 - val_loss: 0.0463\n",
      "Epoch 187/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9860 - loss: 0.0536 - val_accuracy: 0.9838 - val_loss: 0.0486\n",
      "Epoch 188/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9851 - loss: 0.0582 - val_accuracy: 0.9862 - val_loss: 0.0450\n",
      "Epoch 189/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9843 - loss: 0.0549 - val_accuracy: 0.9846 - val_loss: 0.0469\n",
      "Epoch 190/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9880 - loss: 0.0430 - val_accuracy: 0.9869 - val_loss: 0.0438\n",
      "Epoch 191/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9866 - loss: 0.0453 - val_accuracy: 0.9854 - val_loss: 0.0463\n",
      "Epoch 192/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9869 - loss: 0.0496 - val_accuracy: 0.9854 - val_loss: 0.0461\n",
      "Epoch 193/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9858 - loss: 0.0484 - val_accuracy: 0.9854 - val_loss: 0.0446\n",
      "Epoch 194/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9843 - loss: 0.0530 - val_accuracy: 0.9869 - val_loss: 0.0448\n",
      "Epoch 195/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9885 - loss: 0.0425 - val_accuracy: 0.9854 - val_loss: 0.0443\n",
      "Epoch 196/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9886 - loss: 0.0456 - val_accuracy: 0.9831 - val_loss: 0.0502\n",
      "Epoch 197/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9850 - loss: 0.0508 - val_accuracy: 0.9846 - val_loss: 0.0441\n",
      "Epoch 198/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9859 - loss: 0.0498 - val_accuracy: 0.9854 - val_loss: 0.0457\n",
      "Epoch 199/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9832 - loss: 0.0507 - val_accuracy: 0.9869 - val_loss: 0.0490\n",
      "Epoch 200/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9825 - loss: 0.0549 - val_accuracy: 0.9854 - val_loss: 0.0477\n",
      "Epoch 201/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9823 - loss: 0.0485 - val_accuracy: 0.9862 - val_loss: 0.0442\n",
      "Epoch 202/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9892 - loss: 0.0436 - val_accuracy: 0.9823 - val_loss: 0.0521\n",
      "Epoch 203/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9853 - loss: 0.0512 - val_accuracy: 0.9869 - val_loss: 0.0439\n",
      "Epoch 204/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9840 - loss: 0.0527 - val_accuracy: 0.9854 - val_loss: 0.0448\n",
      "Epoch 205/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9846 - loss: 0.0508 - val_accuracy: 0.9846 - val_loss: 0.0439\n",
      "Epoch 206/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9862 - loss: 0.0478 - val_accuracy: 0.9854 - val_loss: 0.0433\n",
      "Epoch 207/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9872 - loss: 0.0421 - val_accuracy: 0.9862 - val_loss: 0.0433\n",
      "Epoch 208/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9857 - loss: 0.0515 - val_accuracy: 0.9854 - val_loss: 0.0444\n",
      "Epoch 209/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9882 - loss: 0.0441 - val_accuracy: 0.9877 - val_loss: 0.0436\n",
      "Epoch 210/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9884 - loss: 0.0429 - val_accuracy: 0.9862 - val_loss: 0.0452\n",
      "Epoch 211/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9820 - loss: 0.0540 - val_accuracy: 0.9862 - val_loss: 0.0441\n",
      "Epoch 212/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9865 - loss: 0.0478 - val_accuracy: 0.9869 - val_loss: 0.0440\n",
      "Epoch 213/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9876 - loss: 0.0461 - val_accuracy: 0.9862 - val_loss: 0.0433\n",
      "Epoch 214/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9899 - loss: 0.0451 - val_accuracy: 0.9862 - val_loss: 0.0442\n",
      "Epoch 215/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9862 - loss: 0.0465 - val_accuracy: 0.9877 - val_loss: 0.0433\n",
      "Epoch 216/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9885 - loss: 0.0407 - val_accuracy: 0.9862 - val_loss: 0.0432\n",
      "Epoch 217/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9842 - loss: 0.0578 - val_accuracy: 0.9862 - val_loss: 0.0440\n",
      "Epoch 218/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9831 - loss: 0.0568 - val_accuracy: 0.9823 - val_loss: 0.0504\n",
      "Epoch 219/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9867 - loss: 0.0424 - val_accuracy: 0.9846 - val_loss: 0.0462\n",
      "Epoch 220/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9861 - loss: 0.0432 - val_accuracy: 0.9815 - val_loss: 0.0534\n",
      "Epoch 221/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9856 - loss: 0.0520 - val_accuracy: 0.9838 - val_loss: 0.0490\n",
      "Epoch 222/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9854 - loss: 0.0512 - val_accuracy: 0.9723 - val_loss: 0.0690\n",
      "Epoch 223/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9829 - loss: 0.0520 - val_accuracy: 0.9815 - val_loss: 0.0511\n",
      "Epoch 224/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9832 - loss: 0.0551 - val_accuracy: 0.9808 - val_loss: 0.0574\n",
      "Epoch 225/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9841 - loss: 0.0468 - val_accuracy: 0.9838 - val_loss: 0.0483\n",
      "Epoch 226/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9829 - loss: 0.0619 - val_accuracy: 0.9846 - val_loss: 0.0471\n",
      "Epoch 227/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9846 - loss: 0.0499 - val_accuracy: 0.9854 - val_loss: 0.0434\n",
      "Epoch 228/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9836 - loss: 0.0512 - val_accuracy: 0.9862 - val_loss: 0.0435\n",
      "Epoch 229/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9886 - loss: 0.0405 - val_accuracy: 0.9846 - val_loss: 0.0436\n",
      "Epoch 230/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9854 - loss: 0.0510 - val_accuracy: 0.9862 - val_loss: 0.0448\n",
      "Epoch 231/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9866 - loss: 0.0406 - val_accuracy: 0.9823 - val_loss: 0.0493\n",
      "Epoch 232/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9858 - loss: 0.0468 - val_accuracy: 0.9846 - val_loss: 0.0448\n",
      "Epoch 233/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9879 - loss: 0.0494 - val_accuracy: 0.9862 - val_loss: 0.0427\n",
      "Epoch 234/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9863 - loss: 0.0409 - val_accuracy: 0.9838 - val_loss: 0.0464\n",
      "Epoch 235/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9897 - loss: 0.0347 - val_accuracy: 0.9862 - val_loss: 0.0448\n",
      "Epoch 236/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9859 - loss: 0.0488 - val_accuracy: 0.9838 - val_loss: 0.0467\n",
      "Epoch 237/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9870 - loss: 0.0467 - val_accuracy: 0.9877 - val_loss: 0.0433\n",
      "Epoch 238/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9858 - loss: 0.0444 - val_accuracy: 0.9862 - val_loss: 0.0430\n",
      "Epoch 239/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9879 - loss: 0.0497 - val_accuracy: 0.9862 - val_loss: 0.0443\n",
      "Epoch 240/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9874 - loss: 0.0415 - val_accuracy: 0.9869 - val_loss: 0.0424\n",
      "Epoch 241/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9882 - loss: 0.0434 - val_accuracy: 0.9854 - val_loss: 0.0438\n",
      "Epoch 242/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9839 - loss: 0.0555 - val_accuracy: 0.9846 - val_loss: 0.0452\n",
      "Epoch 243/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9861 - loss: 0.0475 - val_accuracy: 0.9823 - val_loss: 0.0506\n",
      "Epoch 244/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9835 - loss: 0.0478 - val_accuracy: 0.9823 - val_loss: 0.0477\n",
      "Epoch 245/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9858 - loss: 0.0484 - val_accuracy: 0.9823 - val_loss: 0.0489\n",
      "Epoch 246/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9825 - loss: 0.0603 - val_accuracy: 0.9746 - val_loss: 0.0603\n",
      "Epoch 247/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9831 - loss: 0.0556 - val_accuracy: 0.9823 - val_loss: 0.0519\n",
      "Epoch 248/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9876 - loss: 0.0413 - val_accuracy: 0.9862 - val_loss: 0.0430\n",
      "Epoch 249/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9874 - loss: 0.0387 - val_accuracy: 0.9815 - val_loss: 0.0488\n",
      "Epoch 250/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9839 - loss: 0.0543 - val_accuracy: 0.9854 - val_loss: 0.0451\n",
      "Epoch 251/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9886 - loss: 0.0442 - val_accuracy: 0.9869 - val_loss: 0.0428\n",
      "Epoch 252/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9863 - loss: 0.0442 - val_accuracy: 0.9869 - val_loss: 0.0429\n",
      "Epoch 253/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9863 - loss: 0.0430 - val_accuracy: 0.9854 - val_loss: 0.0424\n",
      "Epoch 254/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9884 - loss: 0.0428 - val_accuracy: 0.9854 - val_loss: 0.0441\n",
      "Epoch 255/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9891 - loss: 0.0385 - val_accuracy: 0.9831 - val_loss: 0.0472\n",
      "Epoch 256/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9862 - loss: 0.0496 - val_accuracy: 0.9846 - val_loss: 0.0454\n",
      "Epoch 257/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9863 - loss: 0.0462 - val_accuracy: 0.9877 - val_loss: 0.0434\n",
      "Epoch 258/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9888 - loss: 0.0371 - val_accuracy: 0.9869 - val_loss: 0.0425\n",
      "Epoch 259/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9859 - loss: 0.0477 - val_accuracy: 0.9862 - val_loss: 0.0432\n",
      "Epoch 260/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9878 - loss: 0.0428 - val_accuracy: 0.9838 - val_loss: 0.0460\n",
      "Epoch 261/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9855 - loss: 0.0498 - val_accuracy: 0.9854 - val_loss: 0.0448\n",
      "Epoch 262/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9877 - loss: 0.0480 - val_accuracy: 0.9869 - val_loss: 0.0432\n",
      "Epoch 263/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9867 - loss: 0.0427 - val_accuracy: 0.9854 - val_loss: 0.0427\n",
      "Epoch 264/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9868 - loss: 0.0414 - val_accuracy: 0.9862 - val_loss: 0.0418\n",
      "Epoch 265/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9847 - loss: 0.0492 - val_accuracy: 0.9823 - val_loss: 0.0487\n",
      "Epoch 266/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9874 - loss: 0.0469 - val_accuracy: 0.9854 - val_loss: 0.0436\n",
      "Epoch 267/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9874 - loss: 0.0499 - val_accuracy: 0.9831 - val_loss: 0.0473\n",
      "Epoch 268/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9868 - loss: 0.0446 - val_accuracy: 0.9846 - val_loss: 0.0437\n",
      "Epoch 269/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9867 - loss: 0.0439 - val_accuracy: 0.9815 - val_loss: 0.0544\n",
      "Epoch 270/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9858 - loss: 0.0501 - val_accuracy: 0.9831 - val_loss: 0.0470\n",
      "Epoch 271/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9862 - loss: 0.0471 - val_accuracy: 0.9831 - val_loss: 0.0450\n",
      "Epoch 272/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9848 - loss: 0.0520 - val_accuracy: 0.9862 - val_loss: 0.0432\n",
      "Epoch 273/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9853 - loss: 0.0468 - val_accuracy: 0.9869 - val_loss: 0.0432\n",
      "Epoch 274/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9890 - loss: 0.0405 - val_accuracy: 0.9838 - val_loss: 0.0534\n",
      "Epoch 275/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9815 - loss: 0.0590 - val_accuracy: 0.9862 - val_loss: 0.0423\n",
      "Epoch 276/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9862 - loss: 0.0529 - val_accuracy: 0.9854 - val_loss: 0.0421\n",
      "Epoch 277/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9882 - loss: 0.0418 - val_accuracy: 0.9862 - val_loss: 0.0418\n",
      "Epoch 278/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9897 - loss: 0.0411 - val_accuracy: 0.9862 - val_loss: 0.0434\n",
      "Epoch 279/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9861 - loss: 0.0461 - val_accuracy: 0.9862 - val_loss: 0.0413\n",
      "Epoch 280/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9917 - loss: 0.0352 - val_accuracy: 0.9862 - val_loss: 0.0413\n",
      "Epoch 281/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9889 - loss: 0.0384 - val_accuracy: 0.9877 - val_loss: 0.0416\n",
      "Epoch 282/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9877 - loss: 0.0376 - val_accuracy: 0.9854 - val_loss: 0.0429\n",
      "Epoch 283/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9864 - loss: 0.0450 - val_accuracy: 0.9862 - val_loss: 0.0436\n",
      "Epoch 284/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9882 - loss: 0.0434 - val_accuracy: 0.9854 - val_loss: 0.0433\n",
      "Epoch 285/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9889 - loss: 0.0465 - val_accuracy: 0.9823 - val_loss: 0.0484\n",
      "Epoch 286/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9874 - loss: 0.0429 - val_accuracy: 0.9854 - val_loss: 0.0415\n",
      "Epoch 287/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9866 - loss: 0.0394 - val_accuracy: 0.9877 - val_loss: 0.0425\n",
      "Epoch 288/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9856 - loss: 0.0469 - val_accuracy: 0.9869 - val_loss: 0.0429\n",
      "Epoch 289/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9883 - loss: 0.0423 - val_accuracy: 0.9846 - val_loss: 0.0445\n",
      "Epoch 290/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9889 - loss: 0.0397 - val_accuracy: 0.9823 - val_loss: 0.0473\n",
      "Epoch 291/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9878 - loss: 0.0416 - val_accuracy: 0.9862 - val_loss: 0.0406\n",
      "Epoch 292/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9865 - loss: 0.0463 - val_accuracy: 0.9854 - val_loss: 0.0414\n",
      "Epoch 293/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9883 - loss: 0.0500 - val_accuracy: 0.9846 - val_loss: 0.0441\n",
      "Epoch 294/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9876 - loss: 0.0417 - val_accuracy: 0.9854 - val_loss: 0.0420\n",
      "Epoch 295/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9894 - loss: 0.0417 - val_accuracy: 0.9838 - val_loss: 0.0466\n",
      "Epoch 296/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9878 - loss: 0.0446 - val_accuracy: 0.9862 - val_loss: 0.0411\n",
      "Epoch 297/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9882 - loss: 0.0443 - val_accuracy: 0.9862 - val_loss: 0.0423\n",
      "Epoch 298/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9892 - loss: 0.0400 - val_accuracy: 0.9862 - val_loss: 0.0436\n",
      "Epoch 299/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9851 - loss: 0.0480 - val_accuracy: 0.9862 - val_loss: 0.0423\n",
      "Epoch 300/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9865 - loss: 0.0481 - val_accuracy: 0.9885 - val_loss: 0.0433\n",
      "Epoch 301/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9857 - loss: 0.0502 - val_accuracy: 0.9862 - val_loss: 0.0409\n",
      "Epoch 302/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9894 - loss: 0.0399 - val_accuracy: 0.9838 - val_loss: 0.0447\n",
      "Epoch 303/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9899 - loss: 0.0383 - val_accuracy: 0.9854 - val_loss: 0.0431\n",
      "Epoch 304/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9895 - loss: 0.0395 - val_accuracy: 0.9862 - val_loss: 0.0419\n",
      "Epoch 305/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9918 - loss: 0.0338 - val_accuracy: 0.9831 - val_loss: 0.0443\n",
      "Epoch 306/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9899 - loss: 0.0474 - val_accuracy: 0.9815 - val_loss: 0.0500\n",
      "Epoch 307/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9871 - loss: 0.0442 - val_accuracy: 0.9831 - val_loss: 0.0450\n",
      "Epoch 308/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9850 - loss: 0.0510 - val_accuracy: 0.9846 - val_loss: 0.0416\n",
      "Epoch 309/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9888 - loss: 0.0401 - val_accuracy: 0.9862 - val_loss: 0.0419\n",
      "Epoch 310/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9871 - loss: 0.0440 - val_accuracy: 0.9846 - val_loss: 0.0416\n",
      "Epoch 311/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9897 - loss: 0.0331 - val_accuracy: 0.9854 - val_loss: 0.0433\n"
     ]
    }
   ],
   "source": [
    "# 학습이 언제 자동 중단될지를 설정합니다.\n",
    "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=20)\n",
    "\n",
    "# 최적화 모델이 저장될 폴더와 모델의 이름을 정합니다.\n",
    "modelpath=\"./data/model/bestmodel.keras\"\n",
    "\n",
    "# 최적화 모델을 업데이트하고 저장합니다.\n",
    "checkpointer = ModelCheckpoint(filepath=modelpath, monitor='val_loss', verbose=0, save_best_only=True)\n",
    "\n",
    "# 모델을 실행합니다.\n",
    "history=model.fit(X_train, y_train, epochs=2000, batch_size=500, validation_split=0.25, verbose=1,\n",
    "                        callbacks=[early_stopping_callback,checkpointer])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 394,
     "status": "ok",
     "timestamp": 1689665278512,
     "user": {
      "displayName": "junhwa lee",
      "userId": "11332889748979012167"
     },
     "user_tz": -540
    },
    "id": "pP0Wcpbb_nG6",
    "outputId": "33ecf917-c894-45bc-b82d-33bdbd1be8d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 968us/step - accuracy: 0.9840 - loss: 0.0447\n",
      "Test accuracy: 0.9823076725006104\n"
     ]
    }
   ],
   "source": [
    "# 테스트 결과를 출력합니다.\n",
    "score=model.evaluate(X_test, y_test)\n",
    "print('Test accuracy:', score[1])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
