{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 웹 스크레이핑"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 웹 브라우저로 웹 사이트 접속하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 하나의 웹 사이트에 접속하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 사이트를 하나 지정한 후에 웹 브라우저를 열어서 접속하는 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import webbrowser\n",
    "\n",
    "url = 'www.naver.com'\n",
    "webbrowser.open(url, new=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 네이버에서 특정 검색어를 입력해 결과 얻기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import webbrowser\n",
    "\n",
    "naver_search_url = \"http://search.naver.com/search.naver?query=\"\n",
    "search_word = '파이썬'\n",
    "url = naver_search_url + search_word\n",
    "\n",
    "webbrowser.open_new(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 구글(Google)에서도 검색을 위한 웹 사이트 주소(www.google.com)와 검색어를 연결 해 입력하면 검색 결과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import webbrowser\n",
    "\n",
    "google_url = \"www.google.com/search?q=\"\n",
    "search_word = 'python'\n",
    "url = google_url + search_word\n",
    "\n",
    "webbrowser.open_new(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 여러 개의 웹 사이트에 접속하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- url 주소 리스트와 for 문을 이용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import webbrowser\n",
    "\n",
    "urls = ['www.naver.com', 'www.daum.net', 'www.google.com']\n",
    "\n",
    "for url in urls:\n",
    "    webbrowser.open_new(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 여러 단어 리스트와 for문 이용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import webbrowser\n",
    "\n",
    "google_url = \"www.google.com/search?q=\"\n",
    "search_words = ['python web scraping', 'python webbrowser']\n",
    "\n",
    "for search_word in search_words:\n",
    "    webbrowser.open_new(google_url + search_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 웹 스크레이핑을 위한 기본 지식"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터의 요청과 응답 과정\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HTML의 기본 구조"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- HTML 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting C:\\Myexam\\HTML_example.html\n"
     ]
    }
   ],
   "source": [
    "%%writefile C:\\Myexam\\HTML_example.html \n",
    "<!doctype html>\n",
    "<html>\n",
    " <head>\n",
    "  <meta charset=\"utf-8\">\n",
    "  <title>이것은 HTML 예제</title>\n",
    " </head>\n",
    " <body>\n",
    "  <h1>출간된 책 정보</h1>\n",
    "  <p id=\"book_title\">이해가 쏙쏙 되는 파이썬</p>\n",
    "  <p id=\"author\">홍길동</p>\n",
    "  <p id=\"publisher\">위키북스 출판사</p>\n",
    "  <p id=\"year\">2018</p>\n",
    " </body>\n",
    "</html>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- HTML 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting C:/Myexam/HTML_example2.html\n"
     ]
    }
   ],
   "source": [
    "%%writefile C:/Myexam/HTML_example2.html \n",
    "<!doctype html>\n",
    "<html>\n",
    " <head>\n",
    "  <meta charset=\"utf-8\">\n",
    "  <title>이것은 HTML 예제</title>\n",
    " </head>\n",
    " <body>\n",
    "  <h1>출간된 책 정보</h1>\n",
    "  <p>이해가 쏙쏙 되는 파이썬</p>\n",
    "  <p>홍길동</p>\n",
    "  <p>위키북스 출판사</p>\n",
    "  <p>2018</p>\n",
    " </body>\n",
    "</html>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 웹 페이지의 HTML 소스 갖고 오기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 구글 웹 페이지(https://www.google.co.kr)의 소스코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "r = requests.get(\"https://www.google.co.kr\")\n",
    "r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 응답 객체를 잘 가져왔는지 확인만 하면 되므로 HTML 파일 전체 중 일부분 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<!doctype html><html itemscope=\"\" itemtype=\"http://schema.org/WebPage\" lang=\"ko\"><head><meta content'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.text[0:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 한번에 수행 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<!doctype html><html itemscope=\"\" itemtype=\"http://schema.org/WebPage\" lang=\"ko\"><head><meta content'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "html = requests.get(\"https://www.google.co.kr\").text\n",
    "html[0:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HTML 소스코드를 분석하고 처리하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 데이터 찾고 추출하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- HTML 코드를 분석해 원하 는 데이터를 추출하는 방법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- HTML 코드를 분석하기 위해서는 HTML 코드 구문을 이해하고 요소별로 HTML 코드를 분류"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Beautiful Soup 라이브 러리를 이용해 HTML 소스를 파싱하고\n",
    "- 태그나 속성을 통해 원하는 데이터를 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<html><body><div><span> <a href=\"http://www.naver.com\">naver</a> <a href=\"https://www.google.com\">google</a> <a href=\"http://www.daum.net/\">daum</a> </span></div></body></html>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# 테스트용 html 코드\n",
    "html = \"\"\"<html><body><div><span>\\\n",
    "        <a href=http://www.naver.com>naver</a>\\\n",
    "        <a href=https://www.google.com>google</a>\\\n",
    "        <a href=http://www.daum.net/>daum</a>\\\n",
    "        </span></div></body></html>\"\"\" \n",
    "\n",
    "# BeautifulSoup를 이용해 HTML 소스를 파싱\n",
    "soup = BeautifulSoup(html, 'lxml') \n",
    "soup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 파싱 결과를 좀 더 보기 편하게 HTML 구조의 형태로 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html>\n",
      " <body>\n",
      "  <div>\n",
      "   <span>\n",
      "    <a href=\"http://www.naver.com\">\n",
      "     naver\n",
      "    </a>\n",
      "    <a href=\"https://www.google.com\">\n",
      "     google\n",
      "    </a>\n",
      "    <a href=\"http://www.daum.net/\">\n",
      "     daum\n",
      "    </a>\n",
      "   </span>\n",
      "  </div>\n",
      " </body>\n",
      "</html>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 파싱한 결과에서 BeautifulSoup.find('태그')를 수행하면 \n",
    "- HTML 소스코드에서 해당 '태그'가 있는 첫 번째 요소를 찾아서 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<a href=\"http://www.naver.com\">naver</a>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find('a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- get_text()는 HTML 소스코드의 요소에서 태그와 속성을 제거하고 텍스트 문자열만 반환\n",
    "- get_text()는 원하는 HTML 요소를 가져온 후에 마지막 단계에서 요소 의 텍스트 부분만 추출할 때 이용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'naver'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find('a').get_text()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- HTML 코드안의 모든 a 태그를 찾아서 a 태그로 시작하는 모든 요소를 다 반환하려면\n",
    "- BeautifulSoup.find_all('태그')를 이용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a href=\"http://www.naver.com\">naver</a>,\n",
       " <a href=\"https://www.google.com\">google</a>,\n",
       " <a href=\"http://www.daum.net/\">daum</a>]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all('a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 태그 이름의 모든 요소를 반환하는 find_all()의 결과는 리스트 형태로 반환\n",
    "- get_text()는 리스트에 적용할 수 없으므로 \n",
    "- for문을 이용해 항목별로 get_text()를 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "naver\n",
      "google\n",
      "daum\n"
     ]
    }
   ],
   "source": [
    "site_names = soup.find_all('a')\n",
    "for site_name in site_names:\n",
    "    print(site_name.get_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- HTML 파일을 작성한 후에 html2 변수에 할당"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# 테스트용 HTML 코드\n",
    "html2 = \"\"\"\n",
    "<html>\n",
    " <head>\n",
    "  <title>작품과 작가 모음</title>\n",
    " </head>\n",
    " <body>\n",
    "  <h1>책 정보</h1>\n",
    "  <p id=\"book_title\">토지</p>\n",
    "  <p id=\"author\">박경리</p>\n",
    "  \n",
    "  <p id=\"book_title\">태백산맥</p>\n",
    "  <p id=\"author\">조정래</p>\n",
    "\n",
    "  <p id=\"book_title\">감옥으로부터의 사색</p>\n",
    "  <p id=\"author\">신영복</p>\n",
    " </body>\n",
    "</html>\n",
    "\"\"\" \n",
    "\n",
    "soup2 = BeautifulSoup(html2, \"lxml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Beautiful Soup의 다양한 기능을 활용해 HTML 소스로부터 필요한 데이터를 추출\n",
    "- HTML 소스에서 title 태그의 요소는 ’BeautifulSoup.title’을 이용해 가져올 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<title>작품과 작가 모음</title>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup2.title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- HTML 소스의 body 태그의 요소는 'BeautiMSoup.body'를 이용해 가져올 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<body>\n",
       "<h1>책 정보</h1>\n",
       "<p id=\"book_title\">토지</p>\n",
       "<p id=\"author\">박경리</p>\n",
       "<p id=\"book_title\">태백산맥</p>\n",
       "<p id=\"author\">조정래</p>\n",
       "<p id=\"book_title\">감옥으로부터의 사색</p>\n",
       "<p id=\"author\">신영복</p>\n",
       "</body>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup2.body"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- body 태그 요소 내에 h1태그의 요소는 'BeautifulSoup.body.h1'로 가져올 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<h1>책 정보</h1>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup2.body.h1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- find_all()을 이용하면 \n",
    "- 변수 html2에 있는 HTML 소스코드에서 p 태그가 들어 간 요소를 모두 가져올 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p id=\"book_title\">토지</p>,\n",
       " <p id=\"author\">박경리</p>,\n",
       " <p id=\"book_title\">태백산맥</p>,\n",
       " <p id=\"author\">조정래</p>,\n",
       " <p id=\"book_title\">감옥으로부터의 사색</p>,\n",
       " <p id=\"author\">신영복</p>]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup2.find_all('p')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- p 태그 중 책 제목과 작가를 분리해서 가져오려면 \n",
    "- find()나 find_all()을 이용할 때 '태그' 뿐만 아니라 \n",
    "- 태그 내의 '속성'도 함께 지정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - BeautifulSoup.find_all('태그',‘속성') \n",
    " - BeautifulSoup.find('태그',‘속성')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- html2의 HTML 코드의 p 태그 요소 중 id가 book_title 인 속성을 갖는 첫 번째 요소만 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<p id=\"book_title\">토지</p>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup2.find('p', {\"id\":\"book_title\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- p 태그 요소 중 id가 author인 속성을 갖는 첫번째 요소만 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<p id=\"author\">박경리</p>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup2.find('p', {\"id\":\"author\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 조건을 만족하는 요소 전체를 가지고 오려면 find_all()을 이용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p id=\"book_title\">토지</p>,\n",
       " <p id=\"book_title\">태백산맥</p>,\n",
       " <p id=\"book_title\">감옥으로부터의 사색</p>]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup2.find_all('p', {\"id\":\"book_title\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p id=\"author\">박경리</p>, <p id=\"author\">조정래</p>, <p id=\"author\">신영복</p>]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup2.find_all('p', {\"id\":\"author\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 책 제목과 작가를 포함한 요소를 각각 추출한 후에 텍스트만 뽑는 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "토지/박경리\n",
      "태백산맥/조정래\n",
      "감옥으로부터의 사색/신영복\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "soup2 = BeautifulSoup(html2, \"lxml\")\n",
    "\n",
    "book_titles = soup2.find_all('p', {\"id\":\"book_title\"})\n",
    "authors = soup2.find_all('p', {\"id\":\"author\"})\n",
    "\n",
    "for book_title, author in zip(book_titles, authors):\n",
    "    print(book_title.get_text() + '/' + author.get_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- CSS 선택자(selector)를 이용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- CSS 선택자는 CSS에서 원하는 요소를 선택 하는 것으로서 파이썬뿐만 아니라 다른 프로그래밍 언어에서도 HTML 소스를 처리할 때 많이 이용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Beautiful Soup도 'BeautifulSoiip.select('태그 및 속성')를 통해 CSS 선택자를 지원\n",
    "- 'BeautifulSoup.select()'의 인자로 '태그 및 속성'을 단계적으로 입력하면 \n",
    "- 원하는 요소를 찾을 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- html2 변수에 할당된 HTML 소스에서 body 태그 요소 내에 M 태그 요소를 가지고 오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<h1>책 정보</h1>]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup2.select('body h1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- body 태그 요소 중에 p 태그를 포함한 요소를 모두 갖고 오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p id=\"book_title\">토지</p>,\n",
       " <p id=\"author\">박경리</p>,\n",
       " <p id=\"book_title\">태백산맥</p>,\n",
       " <p id=\"author\">조정래</p>,\n",
       " <p id=\"book_title\">감옥으로부터의 사색</p>,\n",
       " <p id=\"author\">신영복</p>]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup2.select('body p')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 변수 html2의 HTML 소스에서 p 태그는 body 태그 요소 내에서만 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p id=\"book_title\">토지</p>,\n",
       " <p id=\"author\">박경리</p>,\n",
       " <p id=\"book_title\">태백산맥</p>,\n",
       " <p id=\"author\">조정래</p>,\n",
       " <p id=\"book_title\">감옥으로부터의 사색</p>,\n",
       " <p id=\"author\">신영복</p>]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup2.select('p')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 태그 안의 속성과 속성값을 이용해 요소를 세밀하게 구분해 추출\n",
    "- 태그 안의 속성이 class인 경우 '태그.class_속성값'으로 입력하고 \n",
    "- 속성이 id인 경우에는 '태그#id_속성값'으로 입력해 추출"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 태그 안에 있는 속성이 id이므로 'p#id_속성값'으로 원하는 요소를 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p id=\"book_title\">토지</p>,\n",
       " <p id=\"book_title\">태백산맥</p>,\n",
       " <p id=\"book_title\">감옥으로부터의 사색</p>]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup2.select('p#book_title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p id=\"author\">박경리</p>, <p id=\"author\">조정래</p>, <p id=\"author\">신영복</p>]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup2.select('p#author')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- class 속성이 있는 HTML 소스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting C:/Myexam/HTML_example_my_site.html\n"
     ]
    }
   ],
   "source": [
    "%%writefile C:/Myexam/HTML_example_my_site.html \n",
    "<!doctype html>\n",
    "<html>\n",
    "  <head>\n",
    "    <meta charset=\"utf-8\">\n",
    "    <title>사이트 모음</title>\n",
    "  </head>\n",
    "  <body>\n",
    "    <p id=\"title\"><b>자주 가는 사이트 모음</b></p>\n",
    "    <p id=\"contents\">이곳은 자주 가는 사이트를 모아둔 곳입니다.</p>\n",
    "    <a href=\"http://www.naver.com\" class=\"portal\" id=\"naver\">네이버</a> <br>\n",
    "    <a href=\"https://www.google.com\" class=\"search\" id=\"google\">구글</a> <br>\n",
    "    <a href=\"http://www.daum.net\" class=\"portal\" id=\"daum\">다음</a> <br>\n",
    "    <a href=\"http://www.nl.go.kr\" class=\"government\" id=\"nl\">국립중앙도서관</a>\n",
    "  </body>\n",
    "</html>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 'BeautifulSoup.select('태그 몇 속성')'에서 태그 안의 속성이 class인 경우\n",
    "- '태그.class_속성값'으로 원하는 요소를 추출"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- HTML 소스 파일은 이미 저장돼 있으므로 텍스트 파일을 읽어와서 변수 html3에 할당"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('C:/Myexam/HTML_example_my_site.html', encoding='utf-8')\n",
    "\n",
    "html3 = f.read()\n",
    "f.close()\n",
    "\n",
    "soup3 = BeautifulSoup(html3, \"lxml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 읽어온 HTML 소스에서 태그가 a인 요소를 모두 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a class=\"portal\" href=\"http://www.naver.com\" id=\"naver\">네이버</a>,\n",
       " <a class=\"search\" href=\"https://www.google.com\" id=\"google\">구글</a>,\n",
       " <a class=\"portal\" href=\"http://www.daum.net\" id=\"daum\">다음</a>,\n",
       " <a class=\"government\" href=\"http://www.nl.go.kr\" id=\"nl\">국립중앙도서관</a>]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup3.select('a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- HTML 소스에서 태그가 a이면서 class 속성값이 \"portal\"인 요소만 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a class=\"portal\" href=\"http://www.naver.com\" id=\"naver\">네이버</a>,\n",
       " <a class=\"portal\" href=\"http://www.daum.net\" id=\"daum\">다음</a>]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup3.select('a.portal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 웹 브라우저의 요소 검사"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- soup3.select('html body a’)\n",
    "- soup3.select('body a') \n",
    "- soup3.select('html a') \n",
    "- soup3.select('a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-'BeautifulSoup.select('태그 및 속성')'의 인자로 a만 입력해 태그 a를 포함하는 모든 요소를 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a class=\"portal\" href=\"http://www.naver.com\" id=\"naver\">네이버</a>,\n",
       " <a class=\"search\" href=\"https://www.google.com\" id=\"google\">구글</a>,\n",
       " <a class=\"portal\" href=\"http://www.daum.net\" id=\"daum\">다음</a>,\n",
       " <a class=\"government\" href=\"http://www.nl.go.kr\" id=\"nl\">국립중앙도서관</a>]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup3.select('a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- HTML 소스에서 태그 a를 포함하는 요소 중 class 속성이 \"portal\"인 요소만 선택"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a class=\"portal\" href=\"http://www.naver.com\" id=\"naver\">네이버</a>,\n",
       " <a class=\"portal\" href=\"http://www.daum.net\" id=\"daum\">다음</a>]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup3.select('a.portal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 태그를 포함하는 요소 중 id 속성이 \"naver\" 인 요소를 선택"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a class=\"portal\" href=\"http://www.naver.com\" id=\"naver\">네이버</a>]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup3.select('a#naver')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 줄 바꿈으로 가독성 높이기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- HTML 소스 코드를 파일('br_example_constitution.html')로 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting C:/Myexam/br_example_constitution.html\n"
     ]
    }
   ],
   "source": [
    "%%writefile C:/Myexam/br_example_constitution.html\n",
    "<!doctype html>\n",
    "<html>\n",
    "  <head>\n",
    "    <meta charset=\"utf-8\">\n",
    "    <title>줄 바꿈 테스트 예제</title>\n",
    "  </head>\n",
    "  <body>\n",
    "  <p id=\"title\"><b>대한민국헌법</b></p>\n",
    "  <p id=\"content\">제1조 <br/>①대한민국은 민주공화국이다.<br/>②대한민국의 주권은 국민에게 있고, 모든 권력은 국민으로부터 나온다.</p>\n",
    "  <p id=\"content\">제2조 <br/>①대한민국의 국민이 되는 요건은 법률로 정한다.<br/>②국가는 법률이 정하는 바에 의하여 재외국민을 보호할 의무를 진다.</p>\n",
    "  </body>\n",
    "</html>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- HTML 파일('br_example_constitution.html')을 읽어서 변수 html_source에 할당한 후\n",
    "- 요소에서 텍스트를 주줄하고 줄력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "대한민국헌법\n",
      "제1조 ①대한민국은 민주공화국이다.②대한민국의 주권은 국민에게 있고, 모든 권력은 국민으로부터 나온다.\n",
      "제2조 ①대한민국의 국민이 되는 요건은 법률로 정한다.②국가는 법률이 정하는 바에 의하여 재외국민을 보호할 의무를 진다.\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "f = open('C:/Myexam/br_example_constitution.html', encoding='utf-8')\n",
    "\n",
    "html_source = f.read()\n",
    "f.close()\n",
    "\n",
    "soup = BeautifulSoup(html_source, \"lxml\")\n",
    "\n",
    "title = soup.find('p', {\"id\":\"title\"})\n",
    "contents = soup.find_all('p', {\"id\":\"content\"})\n",
    "\n",
    "print(title.get_text())\n",
    "for content in contents:\n",
    "    print(content.get_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 추출된 HTML 코드에서 줄 바꿈 태그를 파이썬의 개행 문자(\\n)로 바꿈\n",
    "- Beautiful Soup의 'replace_with(새로운 문자열)'를 이용해 \n",
    "- 기존의 태그나 문자열을 새로운 태그나 문자열로 바꿀"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- find_result = BeautifulSoup.find ('태그') \n",
    "- find_result.replace_with('새 태그나 문자열')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- HTML 코드에서 br 태그를 파이썬의 개행문자로 바꾸고 싶으면"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> 태그 p로 찾은 요소\n",
      "<p id=\"content\">제1조 <br/>①대한민국은 민주공화국이다.<br/>②대한민국의 주권은 국민에게 있고, 모든 권력은 국민으로부터 나온다.</p>\n",
      "==> 결과에서 태그 br로 찾은 요소: <br/>\n",
      "==> 태그 br을 개행문자로 바꾼 결과\n",
      "<p id=\"content\">제1조 \n",
      "①대한민국은 민주공화국이다.<br/>②대한민국의 주권은 국민에게 있고, 모든 권력은 국민으로부터 나온다.</p>\n"
     ]
    }
   ],
   "source": [
    "html1 = '<p id=\"content\">제1조 <br/>①대한민국은 민주공화국이다.<br/>②대한민국의 주권은 국민에게 있고, 모든 권력은 국민으로부터 나온다.</p>'\n",
    "\n",
    "soup1 = BeautifulSoup(html1, \"lxml\")\n",
    "\n",
    "print(\"==> 태그 p로 찾은 요소\")\n",
    "content1 = soup1.find('p', {\"id\":\"content\"})\n",
    "print(content1)\n",
    "\n",
    "br_content = content1.find(\"br\")\n",
    "print(\"==> 결과에서 태그 br로 찾은 요소:\", br_content)\n",
    "\n",
    "br_content.replace_with(\"\\n\")\n",
    "print(\"==> 태그 br을 개행문자로 바꾼 결과\")\n",
    "print(content1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 추출된 요소 전체에 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p id=\"content\">제1조 <br/>①대한민국은 민주공화국이다.<br/>②대한민국의 주권은 국민에게 있고, 모든 권력은 국민으로부터 나온다.</p>\n"
     ]
    }
   ],
   "source": [
    "soup2 = BeautifulSoup(html1, \"lxml\")\n",
    "content2 = soup2.find('p', {\"id\":\"content\"})\n",
    "\n",
    "br_contents = content2.find_all(\"br\")\n",
    "for br_content in br_contents:\n",
    "    br_content.replace_with(\"\\n\")\n",
    "print(content2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 함수 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_newline(soup_html):\n",
    "    br_to_newlines = soup_html.find_all(\"br\")\n",
    "    for br_to_newline in br_to_newlines: \n",
    "        br_to_newline.replace_with(\"\\n\")\n",
    "    return soup_html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Beautiful Soup로 파싱된 HTML 소스에서 br 태그를 개행문자(\\n)로 변경\n",
    "- 함수를 이용한 결과에서 요소의 내용만 추출하기 위해 get_text()를 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "제1조 \n",
      "①대한민국은 민주공화국이다.\n",
      "②대한민국의 주권은 국민에게 있고, 모든 권력은 국민으로부터 나온다.\n"
     ]
    }
   ],
   "source": [
    "soup2 = BeautifulSoup(html1, \"lxml\")\n",
    "content2 = soup2.find('p', {\"id\":\"content\"})\n",
    "content3 = replace_newline(content2)\n",
    "print(content3.get_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- HTML 소스코드를 할당한 변수 html_source에 위의 파이씬 코드를 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "대한민국헌법 \n",
      "\n",
      "제1조 \n",
      "①대한민국은 민주공화국이다.\n",
      "②대한민국의 주권은 국민에게 있고, 모든 권력은 국민으로부터 나온다. \n",
      "\n",
      "제2조 \n",
      "①대한민국의 국민이 되는 요건은 법률로 정한다.\n",
      "②국가는 법률이 정하는 바에 의하여 재외국민을 보호할 의무를 진다. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "soup = BeautifulSoup(html_source, \"lxml\")\n",
    "\n",
    "title = soup.find('p', {\"id\":\"title\"})\n",
    "contents = soup.find_all('p', {\"id\":\"content\"})\n",
    "\n",
    "print(title.get_text(), '\\n')\n",
    "\n",
    "for content in contents:\n",
    "    content1 = replace_newline(content)\n",
    "    print(content1.get_text(),'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 줄을 바꾸어 문단을 구분하는 p 태그를 표기하기 위해 \n",
    "- 'content1.get_text()'를 print()로 출력할 때 개행문자{\\n)를 추가"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  웹 사이트에서 데이터 가져오기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 웹 스크레이핑 시 주의 사항"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 웹 페이지의 소스코드에서 데이터를 얻기 위한 규칙을 발견\n",
    "- 파이썬 코드를 이용해 웹 스크레이핑을 할 경우 해당 웹 사이트에 너무 빈번하게 접근 금지\n",
    "- 사이트는 언제든지 예고 없이 변경될 수 있음\n",
    "- 인터넷 상에 공개된 데이터라고 하더라도 저작권(copyright)이 있는 경우가 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 순위 데이터를 가져오기\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 웹 사이트 순위"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 인터넷 사용자들이 방문하는 웹 사이트의 방문 정보(접속한 사용자 수, 페이지 뷰 정보 등) 및 웹 트래 픽을 분석해서\n",
    "- 웹 사이트의 순위를 제공하는 웹 사이트가 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 선정한 select()의 인자 'p a'를 이용해 웹 사이트의 트래픽 순위를 추출"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import requests  \n",
    "from bs4 import BeautifulSoup \n",
    "\n",
    "url = \"https://www.alexa.com/topsites/countries/KR\"\n",
    "\n",
    "html_website_ranking = requests.get(url).text\n",
    "soup_website_ranking = BeautifulSoup(html_website_ranking, \"lxml\")\n",
    "\n",
    "# p 태그의 요소 안에서 a 태그의 요소를 찾음\n",
    "website_ranking = soup_website_ranking.select('p a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 순위 결과가 잘 추출됐는지 알아보기 위해 변수 website_ranking에 저장된 내용 중에서 앞의 일부만 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "website_ranking[0:7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 첫번째 항목을 제외한 리스트 website_ranking[1:]의 각 요소에서 웹 사이트 주소"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "website_ranking[1].get_text()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 리스트의 모든 항목에 대해 get_text()를 적용하기 위해 \n",
    "- 한 줄 for 문을 적용한 리스트 컴프리 헨션을 이용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "website_ranking_address = [website_ranking_element.get_text() for website_ranking_element in website_ranking[1:]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- website_ranking_address 중 앞의 일부만 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "website_ranking_address[0:6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 코드를 통합"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import requests  \n",
    "from bs4 import BeautifulSoup \n",
    "\n",
    "url = \"https://www.alexa.com/topsites/countries/KR\"\n",
    "\n",
    "html_website_ranking = requests.get(url).text\n",
    "soup_website_ranking = BeautifulSoup(html_website_ranking, \"lxml\")\n",
    "\n",
    "# p 태그의 요소 안에서 a 태그의 요소를 찾음\n",
    "website_ranking = soup_website_ranking.select('p a')\n",
    "website_ranking_address = [website_ranking_element.get_text() for website_ranking_element in website_ranking[1:]]\n",
    "\n",
    "print(\"[Top Sites in South Korea]\")\n",
    "for k in range(6):\n",
    "    print(\"{0}: {1}\".format(k+1, website_ranking_address[k]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- pandas의 DataFrame을 이용하면 위의 출력 결과를 좀 더 보기 좋게 만 들 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "\n",
    "website_ranking_dict = {'Website': website_ranking_address}\n",
    "df = pd.DataFrame(website_ranking_dict, columns=['Website'], index=range(1,len(website_ranking_address)+1))\n",
    "df[0:6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 웹 페이지에서 이미지 가져오기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 하나의 이미지 내려받기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- requests 라이브러 리를 이용해 이미지 파일을 위한응답 객체 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests  \n",
    "\n",
    "url = 'https://www.python.org/static/img/python-logo.png'\n",
    "html_image = requests.get(url)\n",
    "html_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 이미지 주소에서 이미지 파일명만 추출해 이용\n",
    "- 이미지 파일의 전체 경로에서 파일 이름만 추출한 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'python-logo.png'"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "image_file_name = os.path.basename(url)\n",
    "image_file_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 이미지 파일을 내 컴퓨터로 내려받을 폴더를 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- os.makedirs(folder)\n",
    "- os.path.exists(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = 'C:/Myexam/download' \n",
    "\n",
    "if not os.path.exists(folder):\n",
    "    os.makedirs(folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 생성된 폴더와 추출한 이미지 파일명을 합치기 위해서 0S모듈의 메서드를 이용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- os.path.join(path1[,path2[,...]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 파일을 저장 하려는폴더가 folder이고 파일 이름이 file이라면 \n",
    "- 'os.path.join(folder, file)'로 파일의 전체 경로를 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 생성한 이미지 파일을 위한 폴더와 추출한 이미지 파일을 통합하는 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:/Myexam/download\\\\python-logo.png'"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_path = os.path.join(folder, image_file_name)\n",
    "image_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - 이미지 파일을 저장하기 전에 우선 open('file_name','mode')을 이용해 파일을 오픈\n",
    " - file_name에는 앞에서 지정한 경로 이름을 넣고\n",
    " - mode에는 쓰기 모드와 바이너리 파일 모드를 지정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 저장하려는 파일이 텍스트 파일이 아니고\n",
    "- 이미지 파일이므로 바이너리 파일 모드로 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "imageFile = open(image_path, 'wb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- requests 라이브러리의 iter_content(chunk_size)를 이용해\n",
    "- 전체 이미지를 chunk_ size [bytes] 만큼나눠서 내려음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 전체 파일의 마지막까지 나눠서 내려받은 데이터를 차례대로 파일 쓰기를 하면\n",
    "- 최종적으로 완전한 하나의 이미지 파일을 내려받을 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 데이터를 1000000 바이트씩 나눠서 내려받고 파일에 순차적으로 저장\n",
    "chunk_size = 1000000\n",
    "for chunk in html_image.iter_content(chunk_size):\n",
    "    imageFile.write(chunk)\n",
    "imageFile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 지정된 폴더의 파일 목록을 보여주는 'os.listdir(folder)'를 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['elements-logo-a914a0d98bda174a3e606aba79073b9c3c2db5075d5742ce48d9fb58186c0858.svg',\n",
       " 'external-link-arrow-9fdf3fbf53535dc5eb554a9a5d5601329bb7bb7169ee72746a37fac0527b2967.svg',\n",
       " 'icon-no-photos-034c2399566c35bc56688f11795abdadf83f3c88fd167216a17ed55c2d65c73e.svg',\n",
       " 'nue-royalty-free-462bfb6f00f39fa826d02345c88ad4f478f7c91e4b7e52b69bf90af33f51e9e7.png',\n",
       " 'python-logo.png',\n",
       " 'reshot-logo--mark-f8dfafbc1cc8fbf4dfa0e2f210265735aefa6e32f883b5a1fe27fd94f84719b3.svg']"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 이미지 주소를 알 경우 이미지 파일을 컴퓨터로 내려받는 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests  \n",
    "import os\n",
    "\n",
    "url = 'https://www.python.org/static/img/python-logo.png'\n",
    "html_image = requests.get(url)\n",
    "image_file_name = os.path.basename(url)\n",
    "\n",
    "folder = 'C:/Myexam/download' \n",
    "\n",
    "if not os.path.exists(folder):\n",
    "    os.makedirs(folder)\n",
    "\n",
    "image_path = os.path.join(folder, image_file_name)\n",
    "\n",
    "imageFile = open(image_path, 'wb')\n",
    "# 이미지 데이터를 1000000 바이트씩 나눠서 저장\n",
    "chunk_size = 1000000\n",
    "for chunk in html_image.iter_content(chunk_size):\n",
    "    imageFile.write(chunk)\n",
    "imageFile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 여러 이미지 내려받기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- select('a img')를 수행하면 해당 이미지의 요소가 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<img alt=\"Reshot\" height=\"33\" src=\"https://www.reshot.com/build/reshot-logo--mark-f8dfafbc1cc8fbf4dfa0e2f210265735aefa6e32f883b5a1fe27fd94f84719b3.svg\" title=\"Reshot\" width=\"46\"/>,\n",
       " <img alt=\"External link\" height=\"16\" loading=\"lazy\" src=\"https://www.reshot.com/build/photos/external-link-arrow-9fdf3fbf53535dc5eb554a9a5d5601329bb7bb7169ee72746a37fac0527b2967.svg\" width=\"16\"/>,\n",
       " <img alt=\"External link\" height=\"16\" loading=\"lazy\" src=\"https://www.reshot.com/build/photos/external-link-arrow-9fdf3fbf53535dc5eb554a9a5d5601329bb7bb7169ee72746a37fac0527b2967.svg\" width=\"16\"/>,\n",
       " <img alt=\"Reshot\" class=\"global-footer__logo-image\" height=\"82\" src=\"https://www.reshot.com/build/reshot-logo--mark-f8dfafbc1cc8fbf4dfa0e2f210265735aefa6e32f883b5a1fe27fd94f84719b3.svg\" title=\"Reshot\" width=\"113\"/>]"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests  \n",
    "from bs4 import BeautifulSoup \n",
    "\n",
    "URL = 'https://reshot.com/search/animal'\n",
    "\n",
    "html_reshot_image = requests.get(URL).text\n",
    "soup_reshot_image = BeautifulSoup(html_reshot_image, \"lxml\")\n",
    "reshot_image_elements = soup_reshot_image.select('a img') \n",
    "reshot_image_elements[0:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 출력 결과를 보면 img 태그가 포함된 이미지가 있는 요소가 추출\n",
    "- 리스트 reshot_image_elements의 제일 첫 번째 요소는 reshot의 로고 이미지\n",
    "- 동물 이미지만 가져오기 위해서는 reshot_image_elements[1:]을 이용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- BeautifulSoup에서 get('속성')은 '속성'에 들어간 '속성값'을 반환\n",
    "- 추출된 요소에서 src 의 속성값인 이미지 주소를 구하려면 get('src')을 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.reshot.com/build/photos/external-link-arrow-9fdf3fbf53535dc5eb554a9a5d5601329bb7bb7169ee72746a37fac0527b2967.svg'"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reshot_image_url = reshot_image_elements[1].get('src')\n",
    "reshot_image_url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 이미지의 주소를 알 고 있을 때 이미지를 내려받는 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_image = requests.get(reshot_image_url)\n",
    "\n",
    "folder = \"C:/Myexam/download\"\n",
    "    \n",
    "# os.path.basename(URL)는 웹사이트나 폴더가 포함된 파일명에서 파일명만 분리하는 방법    \n",
    "imageFile = open(os.path.join(folder, os.path.basename(reshot_image_url)), 'wb')\n",
    "\n",
    "# 이미지 데이터를 1000000 바이트씩 나눠서 저장하는 방법\n",
    "chunk_size = 1000000 \n",
    "for chunk in html_image.iter_content(chunk_size):\n",
    "    imageFile.write(chunk)\n",
    "imageFile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 함수로 만들고 반복문으로 지정한 개수만큼 이미지를 내려받는 코드를 작성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 파일명: 'reshot-logo--mark-f8dfafbc1cc8fbf4dfa0e2f210265735aefa6e32f883b5a1fe27fd94f84719b3.svg'. 내려받기 완료!\n",
      "이미지 파일명: 'icon-no-photos-034c2399566c35bc56688f11795abdadf83f3c88fd167216a17ed55c2d65c73e.svg'. 내려받기 완료!\n",
      "이미지 파일명: 'external-link-arrow-9fdf3fbf53535dc5eb554a9a5d5601329bb7bb7169ee72746a37fac0527b2967.svg'. 내려받기 완료!\n",
      "이미지 파일명: 'nue-royalty-free-462bfb6f00f39fa826d02345c88ad4f478f7c91e4b7e52b69bf90af33f51e9e7.png'. 내려받기 완료!\n",
      "이미지 파일명: 'elements-logo-a914a0d98bda174a3e606aba79073b9c3c2db5075d5742ce48d9fb58186c0858.svg'. 내려받기 완료!\n",
      "이미지 파일명: 'external-link-arrow-9fdf3fbf53535dc5eb554a9a5d5601329bb7bb7169ee72746a37fac0527b2967.svg'. 내려받기 완료!\n",
      "이미지 파일명: 'reshot-logo--mark-f8dfafbc1cc8fbf4dfa0e2f210265735aefa6e32f883b5a1fe27fd94f84719b3.svg'. 내려받기 완료!\n",
      "================================\n",
      "선택한 모든 이미지 내려받기 완료!\n"
     ]
    }
   ],
   "source": [
    "import requests  \n",
    "from bs4 import BeautifulSoup \n",
    "import os\n",
    "\n",
    "# URL(주소)에서 이미지 주소 추출\n",
    "def get_image_url(url): \n",
    "    html_image_url = requests.get(url).text\n",
    "    soup_image_url = BeautifulSoup(html_image_url, \"lxml\")  \n",
    "    image_elements = soup_image_url.select('img') \n",
    "    if(image_elements != None):\n",
    "        image_urls = []\n",
    "        for image_element in image_elements:\n",
    "            image_urls.append(image_element.get('src'))\n",
    "        return image_urls        \n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "# 폴더를 지정해 이미지 주소에서 이미지 내려받기\n",
    "def download_image(img_folder, img_url):\n",
    "    if(img_url != None):  \n",
    "        html_image = requests.get(img_url)\n",
    "        # os.path.basename(URL)는 웹사이트나 폴더가 포함된 파일명에서 파일명만 분리    \n",
    "        imageFile = open(os.path.join(img_folder, os.path.basename(img_url)), 'wb')\n",
    "\n",
    "        chunk_size = 1000000 # 이미지 데이터를 1000000 바이트씩 나눠서 저장\n",
    "        for chunk in html_image.iter_content(chunk_size):\n",
    "            imageFile.write(chunk)\n",
    "        imageFile.close()\n",
    "        print(\"이미지 파일명: '{0}'. 내려받기 완료!\".format(os.path.basename(img_url))) \n",
    "    else:       \n",
    "        print(\"내려받을 이미지가 없습니다.\")\n",
    "        \n",
    "# 웹 사이트의 주소 지정   \n",
    "reshot_url = 'https://www.reshot.com/search/animal'\n",
    "\n",
    "\n",
    "figure_folder = \"C:/Myexam/download\" # 이미지를 내려받을 폴더 지정  \n",
    "\n",
    "reshot_image_urls = get_image_url(reshot_url) # 이미지 파일의 주소 가져오기\n",
    "\n",
    "num_of_download_image = 7 # 내려받을 이미지 개수 지정\n",
    "# num_of_download_image = len(reshot_image_urls)\n",
    "\n",
    "for k in range(num_of_download_image):\n",
    "    download_image(figure_folder,reshot_image_urls[k])\n",
    "print(\"================================\")\n",
    "print(\"선택한 모든 이미지 내려받기 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- len(reshot_image_urls)로 이미지가 몇 개인지 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_of_download_image = len(reshot_image_urls)\n",
    "num_of_download_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "정리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- webbrowser 라이브러리를 이용해 원하는 웹 사이트를 웹 브라우저로 열어서 접속하는 방법\n",
    "- HTML 코드를 분석하고 requests 라이브러리를 이용해 HTML 소스를 가져오는 방법\n",
    "- HTML 소스를 Beautiful Soup 라이브러리를 이용해 파싱하고 원하는 결과를 추출하는 방법\n",
    "- 웹 사이트에 있는 이미지 파일을 내려받는 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 에러 리스트\n",
    " - 경로 실습 파일 그대로 할꺼면 Myexam 폴더를 만들어둘것\n",
    " - download_image 함수에서 imageFile.close()를 for문 밖으로 빼야함 (이미지를 다 받기전에 close하면 오류가 발생)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "nav_menu": {},
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "400px",
    "width": "252px"
   },
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "545px",
    "left": "0px",
    "right": "1154px",
    "top": "111px",
    "width": "212px"
   },
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "toc_position": {
   "height": "503px",
   "left": "0px",
   "right": "952.167px",
   "top": "107px",
   "width": "300px"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
